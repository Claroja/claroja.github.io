const t=JSON.parse('{"key":"v-18c90493","path":"/8%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/3spark/%E5%9F%BA%E7%A1%80/intro.html","title":"intro","lang":"zh-CN","frontmatter":{"description":"intro Spark Apache Spark是用于大规模数据（large-scala data）处理的统一（unified）分析引擎。最早源于一篇论文: Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing. spark vs hadoop xxx hadoop spark 类型 平台:包含计算,存储,调度 计算 场景 磁盘批处理 内存批处理和流处理 存储 MapReduce中间结果存储在HDFS,延迟大 RDD中间结果存储在内存,延迟小 运行方式 Task以进程方式维护，启动慢 Task以线程方式维护，启动快","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/8%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/3spark/%E5%9F%BA%E7%A1%80/intro.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"intro"}],["meta",{"property":"og:description","content":"intro Spark Apache Spark是用于大规模数据（large-scala data）处理的统一（unified）分析引擎。最早源于一篇论文: Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing. spark vs hadoop xxx hadoop spark 类型 平台:包含计算,存储,调度 计算 场景 磁盘批处理 内存批处理和流处理 存储 MapReduce中间结果存储在HDFS,延迟大 RDD中间结果存储在内存,延迟小 运行方式 Task以进程方式维护，启动慢 Task以线程方式维护，启动快"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://claroja.github.io/"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-24T12:46:58.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"intro"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-24T12:46:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"intro\\",\\"image\\":[\\"https://claroja.github.io/\\"],\\"dateModified\\":\\"2025-02-24T12:46:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"spark vs hadoop","slug":"spark-vs-hadoop","link":"#spark-vs-hadoop","children":[]},{"level":2,"title":"spark role","slug":"spark-role","link":"#spark-role","children":[]},{"level":2,"title":"集群模式","slug":"集群模式","link":"#集群模式","children":[]},{"level":2,"title":"python on spark 原理","slug":"python-on-spark-原理","link":"#python-on-spark-原理","children":[]}],"git":{"createdTime":1740401218000,"updatedTime":1740401218000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":2.2,"words":660},"filePathRelative":"8数据工程/3spark/基础/intro.md","localizedDate":"2025年2月24日","excerpt":"<h1> intro</h1>\\n<p>Spark Apache Spark是用于大规模数据（large-scala data）处理的统一（unified）分析引擎。最早源于一篇论文: Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing.</p>\\n<figure><figcaption></figcaption></figure>\\n<h2> spark vs hadoop</h2>\\n<table>\\n<thead>\\n<tr>\\n<th>xxx</th>\\n<th>hadoop</th>\\n<th>spark</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>类型</td>\\n<td>平台:包含计算,存储,调度</td>\\n<td>计算</td>\\n</tr>\\n<tr>\\n<td>场景</td>\\n<td>磁盘批处理</td>\\n<td>内存批处理和流处理</td>\\n</tr>\\n<tr>\\n<td>存储</td>\\n<td>MapReduce中间结果存储在HDFS,延迟大</td>\\n<td>RDD中间结果存储在内存,延迟小</td>\\n</tr>\\n<tr>\\n<td>运行方式</td>\\n<td>Task以进程方式维护，启动慢</td>\\n<td>Task以线程方式维护，启动快</td>\\n</tr>\\n</tbody>\\n</table>","copyright":{"author":"王新宇"},"autoDesc":true}');export{t as data};
