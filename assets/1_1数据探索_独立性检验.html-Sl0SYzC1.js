const n=JSON.parse(`{"key":"v-17eb153a","path":"/1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B/1%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/1_1%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2_%E7%8B%AC%E7%AB%8B%E6%80%A7%E6%A3%80%E9%AA%8C.html","title":"独立性检验","lang":"zh-CN","frontmatter":{"description":"独立性检验 最佳实践 分析特征的相关性, 用来填补缺失数据 分析特征目标的相关性, 来筛选特征 两个分类变量使用卡方检验 import pandas as pd from scipy.stats import chi2_contingency df = pd.DataFrame({'Gender' : ['M', 'M', 'M', 'F', 'F'] * 10, 'isSmoker' : ['Smoker', 'Smoker', 'Non-Smpoker', 'Non-Smpoker', 'Smoker'] * 10 }) contigency= pd.crosstab(df['Gender'], df['isSmoker']) contigency_pct = pd.crosstab(df['Gender'], df['isSmoker'], normalize='index') c, p, dof, expected = chi2_contingency(contigency) p # 0.3767591178115821","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B/1%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/1_1%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2_%E7%8B%AC%E7%AB%8B%E6%80%A7%E6%A3%80%E9%AA%8C.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"独立性检验"}],["meta",{"property":"og:description","content":"独立性检验 最佳实践 分析特征的相关性, 用来填补缺失数据 分析特征目标的相关性, 来筛选特征 两个分类变量使用卡方检验 import pandas as pd from scipy.stats import chi2_contingency df = pd.DataFrame({'Gender' : ['M', 'M', 'M', 'F', 'F'] * 10, 'isSmoker' : ['Smoker', 'Smoker', 'Non-Smpoker', 'Non-Smpoker', 'Smoker'] * 10 }) contigency= pd.crosstab(df['Gender'], df['isSmoker']) contigency_pct = pd.crosstab(df['Gender'], df['isSmoker'], normalize='index') c, p, dof, expected = chi2_contingency(contigency) p # 0.3767591178115821"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-25T10:13:52.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-25T10:13:52.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"独立性检验\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-25T10:13:52.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"最佳实践","slug":"最佳实践","link":"#最佳实践","children":[]},{"level":2,"title":"两个分类变量使用卡方检验","slug":"两个分类变量使用卡方检验","link":"#两个分类变量使用卡方检验","children":[]},{"level":2,"title":"两个连续变量","slug":"两个连续变量","link":"#两个连续变量","children":[]},{"level":2,"title":"分类变量与连续变变量","slug":"分类变量与连续变变量","link":"#分类变量与连续变变量","children":[]},{"level":2,"title":"参考","slug":"参考","link":"#参考","children":[]}],"git":{"createdTime":1740478432000,"updatedTime":1740478432000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":1.32,"words":395},"filePathRelative":"1机器学习/1算法原理/2机器学习流程/1数据探索/1_1数据探索_独立性检验.md","localizedDate":"2025年2月25日","excerpt":"<h1> 独立性检验</h1>\\n<h2> 最佳实践</h2>\\n<ol>\\n<li>分析特征的相关性, 用来填补缺失数据</li>\\n<li>分析特征目标的相关性, 来筛选特征</li>\\n</ol>\\n<h2> 两个分类变量使用卡方检验</h2>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">import</span> pandas <span class=\\"token keyword\\">as</span> pd\\n<span class=\\"token keyword\\">from</span> scipy<span class=\\"token punctuation\\">.</span>stats <span class=\\"token keyword\\">import</span> chi2_contingency\\n\\ndf <span class=\\"token operator\\">=</span> pd<span class=\\"token punctuation\\">.</span>DataFrame<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">{</span><span class=\\"token string\\">'Gender'</span> <span class=\\"token punctuation\\">:</span> <span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'M'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'M'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'M'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'F'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'F'</span><span class=\\"token punctuation\\">]</span> <span class=\\"token operator\\">*</span> <span class=\\"token number\\">10</span><span class=\\"token punctuation\\">,</span>\\n                   <span class=\\"token string\\">'isSmoker'</span> <span class=\\"token punctuation\\">:</span> <span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'Smoker'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'Smoker'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'Non-Smpoker'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'Non-Smpoker'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'Smoker'</span><span class=\\"token punctuation\\">]</span> <span class=\\"token operator\\">*</span> <span class=\\"token number\\">10</span>\\n                  <span class=\\"token punctuation\\">}</span><span class=\\"token punctuation\\">)</span>\\n\\ncontigency<span class=\\"token operator\\">=</span> pd<span class=\\"token punctuation\\">.</span>crosstab<span class=\\"token punctuation\\">(</span>df<span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'Gender'</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> df<span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'isSmoker'</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span>\\ncontigency_pct <span class=\\"token operator\\">=</span> pd<span class=\\"token punctuation\\">.</span>crosstab<span class=\\"token punctuation\\">(</span>df<span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'Gender'</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> df<span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'isSmoker'</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> normalize<span class=\\"token operator\\">=</span><span class=\\"token string\\">'index'</span><span class=\\"token punctuation\\">)</span>\\nc<span class=\\"token punctuation\\">,</span> p<span class=\\"token punctuation\\">,</span> dof<span class=\\"token punctuation\\">,</span> expected <span class=\\"token operator\\">=</span> chi2_contingency<span class=\\"token punctuation\\">(</span>contigency<span class=\\"token punctuation\\">)</span>\\np  <span class=\\"token comment\\"># 0.3767591178115821</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","copyright":{"author":"王新宇"},"autoDesc":true}`);export{n as data};
