import{_ as o}from"./plugin-vue_export-helper-x3n3nnut.js";import{r,o as c,c as p,a as n,b as e,d as t,e as a}from"./app-SnI5rGHA.js";const i={},d=n("h1",{id:"bert",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#bert","aria-hidden":"true"},"#"),e(" bert")],-1),l=n("p",null,[n("code",null,"BertForSequenceClassification"),e("是"),n("code",null,"BertModel"),e("的进一步封装")],-1),u=n("h2",{id:"bertmodel",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#bertmodel","aria-hidden":"true"},"#"),e(" BertModel")],-1),k={href:"https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel",target:"_blank",rel:"noopener noreferrer"},m=a(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizer<span class="token punctuation">,</span> BertModel
<span class="token keyword">import</span> torch
tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;bert-base-uncased&quot;</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> BertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;bert-base-uncased&quot;</span><span class="token punctuation">)</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">&quot;Hello, my dog is cute&quot;</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>input_ids</td><td><code>Tokenizer</code>的返回结果</td></tr><tr><td>attention_mask</td><td><code>Tokenizer</code>的返回结果</td></tr><tr><td>token_type_ids</td><td><code>Tokenizer</code>的返回结果</td></tr><tr><td>position_ids</td><td><code>Tokenizer</code>的返回结果</td></tr></tbody></table><h2 id="bertforsequenceclassification" tabindex="-1"><a class="header-anchor" href="#bertforsequenceclassification" aria-hidden="true">#</a> BertForSequenceClassification</h2>`,3),b={href:"https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForSequenceClassification",target:"_blank",rel:"noopener noreferrer"},h=a(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>num_labels <span class="token operator">=</span> <span class="token number">8</span>
model <span class="token operator">=</span> BertForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;model_name&quot;</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span>num_labels<span class="token punctuation">)</span>
labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> labels<span class="token operator">=</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span>loss
<span class="token builtin">round</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>input_ids</td><td><code>Tokenizer</code>的返回结果</td></tr><tr><td>attention_mask</td><td><code>Tokenizer</code>的返回结果</td></tr><tr><td>token_type_ids</td><td><code>Tokenizer</code>的返回结果</td></tr><tr><td>position_ids</td><td><code>Tokenizer</code>的返回结果</td></tr><tr><td>labels</td><td>如果<code>num_labels=1</code>则计算regression loss, <code>Mean-Square loss</code>, 如果<code>num_labels&gt;1</code>则计算classification loss, <code>Cross-Entropy</code></td></tr></tbody></table>`,2);function _(f,v){const s=r("ExternalLinkIcon");return c(),p("div",null,[d,l,u,n("p",null,[n("a",k,[e("BertModel"),t(s)]),e(" The bare Bert Model transformer outputting raw hidden-states without any specific head on top.")]),m,n("p",null,[n("a",b,[e("BertForSequenceClassification"),t(s)]),e(" Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for GLUE tasks.")]),h])}const y=o(i,[["render",_],["__file","bert.html.vue"]]);export{y as default};
