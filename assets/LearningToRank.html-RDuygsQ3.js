import{_ as e}from"./plugin-vue_export-helper-x3n3nnut.js";import{o,c as t,e as i}from"./app-SnI5rGHA.js";const n={},a=i('<h1 id="learningtorank" tabindex="-1"><a class="header-anchor" href="#learningtorank" aria-hidden="true">#</a> LearningToRank</h1><p>this task arises in many other applications:</p><ol><li>Search Engines — Given a user profile (location, age, sex, …) a textual query, sort web pages results by relevance.</li><li>Recommender Systems — Given a user profile and purchase history, sort the other items to find new potentially interesting products for the user.</li></ol><p>Ranking models typically work by predicting a relevance score <code>s = f(x)</code> for each input <code>x = (q, d)</code> where <code>q</code> is a <code>query</code> and <code>d</code> is a <code>document</code>. Once we have the relevance of each document, we can sort (i.e. rank) the documents according to those scores.</p><p>The scoring model can be implemented using various approaches:</p><ol><li><code>Vector Space Models</code> – Compute a vector embedding (e.g. using <code>Tf-Idf</code> or <code>BERT</code>) for each query and document, and then compute the relevance score <code>f(x) = f(q, d)</code> as the cosine similarity between the vectors embeddings of <code>q</code> and <code>d</code>.</li><li><code>Learning to Rank</code> – The scoring model is a Machine Learning model that learns to predict a score s given an input <code>x = (q, d)</code> during a training phase where some sort of ranking loss is minimized.</li></ol><h2 id="evaluation" tabindex="-1"><a class="header-anchor" href="#evaluation" aria-hidden="true">#</a> Evaluation</h2><p>define <code>inputs</code>, <code>outputs</code> and <code>loss function</code>.</p><ol><li><code>Input</code> – For a query <code>q</code> we have <code>n</code> documents <code>D = {d₁, …, dₙ}</code> to be ranked by relevance. The elements <code>xᵢ = (q, dᵢ)</code> are the inputs to our model.</li><li><code>Output</code> - For a query-document input <code>xᵢ = (q, dᵢ)</code>, we assume there exists a true relevance score <code>yᵢ</code>. Our model outputs a predicted score <code>sᵢ = f(xᵢ)</code>.</li></ol><h2 id="machine-learning-models-to-rank" tabindex="-1"><a class="header-anchor" href="#machine-learning-models-to-rank" aria-hidden="true">#</a> Machine Learning Models to Rank</h2><p>The choice of the loss function is the distinctive element for Learning to Rank models.</p><ol><li><p>Pointwise Methods – The total loss is computed as the sum of loss terms defined on each document <code>dᵢ</code> (hence pointwise) as the distance between the predicted score <code>sᵢ</code> and the ground truth <code>yᵢ</code>, for <code>i=1…n</code>. By doing this, we transform our task into a <code>regression problem</code>, where we train a model to predict y.</p></li><li><p>Pairwise Methods – The total loss is computed as the sum of loss terms defined on each pair of documents <code>dᵢ</code>, <code>dⱼ</code> (hence pairwise) , for <code>i, j=1…n</code>. The objective on which the model is trained is to predict whether <code>yᵢ &gt; yⱼ</code> or not, i.e. which of two documents is more relevant. By doing this, we transform our task into a binary classification problem.</p></li><li><p>Listwise Methods – The loss is directly computed on the whole list of documents (hence listwise) with corresponding predicted ranks. In this way, ranking metrics can be more directly incorporated into the loss.</p></li></ol><figure><img src="https://miro.medium.com/max/1400/1*s3CQuNRWcQNkQKd8Met-MA.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="pointwise-methods" tabindex="-1"><a class="header-anchor" href="#pointwise-methods" aria-hidden="true">#</a> Pointwise Methods</h2><p>The loss directly measures the distance between ground true score yᵢ and predicted sᵢ so we treat this task by effectively solving a regression problem.loss function is <code>Mean Square Error (MSE)</code></p><p>shortcomings: we only know which document in a list of documents was chosen by a user (and therefore is more relevant), but we don’t know exactly how relevant is any of these documents!</p><h2 id="pairwise-methods" tabindex="-1"><a class="header-anchor" href="#pairwise-methods" aria-hidden="true">#</a> Pairwise Methods</h2><h3 id="ranknet" tabindex="-1"><a class="header-anchor" href="#ranknet" aria-hidden="true">#</a> RankNet</h3><p>given two documents, we want to predict if the first is more relevant than the second. This way we solve a binary classification task where we only need the ground truth <code>yᵢⱼ (=1 if yᵢ &gt; yⱼ, 0 otherwise)</code> and we map from the model outputs to probabilities using a logistic function: <code>sᵢⱼ = σ(sᵢ – sⱼ)</code>.This approach was first used by <code>RankNet</code>, which used a <code>Binary Cross Entropy (BCE)</code> loss.</p><p>shortcoming: RankNet is an improvement over pointwise methods, but all documents are still given the same importance during training, while we would want to give more importance to documents in higher ranks (as the DCG metric does with the discount terms).</p><h3 id="lambdarank" tabindex="-1"><a class="header-anchor" href="#lambdarank" aria-hidden="true">#</a> LambdaRank</h3><p>to run Gradient Descent optimization we don’t need a loss function, we only need its gradient! LambdaRank defines the gradients of an implicit loss function so that documents with high rank have much bigger gradients:</p><h2 id="listwise-methods" tabindex="-1"><a class="header-anchor" href="#listwise-methods" aria-hidden="true">#</a> Listwise Methods</h2><p>refs: https://towardsdatascience.com/learning-to-rank-a-complete-guide-to-ranking-using-machine-learning-4c9688d370d4 https://queirozf.com/entries/evaluation-metrics-for-ranking-problems-introduction-and-examples</p>',24),s=[a];function d(r,c){return o(),t("div",null,s)}const m=e(n,[["render",d],["__file","LearningToRank.html.vue"]]);export{m as default};
