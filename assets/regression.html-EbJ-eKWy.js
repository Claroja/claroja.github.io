const e=JSON.parse('{"key":"v-7acb1ab1","path":"/%E6%9C%AA%E5%88%86%E7%B1%BB/regression.html","title":"regression","lang":"zh-CN","frontmatter":{"description":"regression 总结 第一步和GBDT一样是做一个初始化的预测，一般是均值 第二步和GBDT一样是创建一棵树来拟合残差，XGBOOST在拟合的时候 推导 NOTE:XGBoost was designed to be used with large, complicated data sets. On the x-axis, we have different drug dosages and on the y-axis, we measured drug effectiveness.","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/%E6%9C%AA%E5%88%86%E7%B1%BB/regression.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"regression"}],["meta",{"property":"og:description","content":"regression 总结 第一步和GBDT一样是做一个初始化的预测，一般是均值 第二步和GBDT一样是创建一棵树来拟合残差，XGBOOST在拟合的时候 推导 NOTE:XGBoost was designed to be used with large, complicated data sets. On the x-axis, we have different drug dosages and on the y-axis, we measured drug effectiveness."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://claroja.github.io/"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-11-27T13:31:52.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"regression"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2023-11-27T13:31:52.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"regression\\",\\"image\\":[\\"https://claroja.github.io/\\"],\\"dateModified\\":\\"2023-11-27T13:31:52.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]},{"level":2,"title":"推导","slug":"推导","link":"#推导","children":[]},{"level":2,"title":"prune","slug":"prune","link":"#prune","children":[]},{"level":2,"title":"lambda","slug":"lambda","link":"#lambda","children":[]},{"level":2,"title":"output","slug":"output","link":"#output","children":[]},{"level":2,"title":"gradient","slug":"gradient","link":"#gradient","children":[]}],"git":{"createdTime":1701091021000,"updatedTime":1701091912000,"contributors":[{"name":"claroja","email":"63183535@qq.com","commits":2}]},"readingTime":{"minutes":4.66,"words":1398},"filePathRelative":"未分类/regression.md","localizedDate":"2023年11月27日","excerpt":"<h1> regression</h1>\\n<h2> 总结</h2>\\n<ol>\\n<li>第一步和GBDT一样是做一个初始化的预测，一般是均值</li>\\n<li>第二步和GBDT一样是创建一棵树来拟合残差，XGBOOST在拟合的时候</li>\\n</ol>\\n<h2> 推导</h2>\\n<p>NOTE:XGBoost was designed to be used with large, complicated data sets.</p>\\n<p>On the x-axis, we have different <code>drug dosages</code> and on the y-axis, we measured <code>drug effectiveness</code>.\\n</p>","copyright":{"author":"王新宇"},"autoDesc":true}');export{e as data};
