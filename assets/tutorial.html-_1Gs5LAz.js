const e=JSON.parse(`{"key":"v-badbcd66","path":"/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/5pytorch/%E5%AE%98%E7%BD%91%E7%BF%BB%E8%AF%91/tutorial.html","title":"tutorial","lang":"zh-CN","frontmatter":{"description":"tutorial gpu则用gpu, 否则使用cpu. device = 'cuda' if torch.cuda.is_available() else 'cpu' print('Using {} device'.format(device))","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/5pytorch/%E5%AE%98%E7%BD%91%E7%BF%BB%E8%AF%91/tutorial.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"tutorial"}],["meta",{"property":"og:description","content":"tutorial gpu则用gpu, 否则使用cpu. device = 'cuda' if torch.cuda.is_available() else 'cpu' print('Using {} device'.format(device))"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-24T12:46:58.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-24T12:46:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"tutorial\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-24T12:46:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"Define the Class","slug":"define-the-class","link":"#define-the-class","children":[]},{"level":2,"title":"Model Layers","slug":"model-layers","link":"#model-layers","children":[{"level":3,"title":"nn.Flatten","slug":"nn-flatten","link":"#nn-flatten","children":[]},{"level":3,"title":"nn.Linear","slug":"nn-linear","link":"#nn-linear","children":[]},{"level":3,"title":"nn.ReLU","slug":"nn-relu","link":"#nn-relu","children":[]},{"level":3,"title":"nn.Sequential","slug":"nn-sequential","link":"#nn-sequential","children":[]},{"level":3,"title":"nn.Softmax","slug":"nn-softmax","link":"#nn-softmax","children":[]}]},{"level":2,"title":"Model Parameters","slug":"model-parameters","link":"#model-parameters","children":[]}],"git":{"createdTime":1740401218000,"updatedTime":1740401218000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":1.72,"words":516},"filePathRelative":"2机器学习/3分析工具/5pytorch/官网翻译/tutorial.md","localizedDate":"2025年2月24日","excerpt":"<h1> tutorial</h1>\\n<p>gpu则用gpu, 否则使用cpu.</p>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code>device <span class=\\"token operator\\">=</span> <span class=\\"token string\\">'cuda'</span> <span class=\\"token keyword\\">if</span> torch<span class=\\"token punctuation\\">.</span>cuda<span class=\\"token punctuation\\">.</span>is_available<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span> <span class=\\"token keyword\\">else</span> <span class=\\"token string\\">'cpu'</span>\\n<span class=\\"token keyword\\">print</span><span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'Using {} device'</span><span class=\\"token punctuation\\">.</span><span class=\\"token builtin\\">format</span><span class=\\"token punctuation\\">(</span>device<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","copyright":{"author":"王新宇"},"autoDesc":true}`);export{e as data};
