const e=JSON.parse('{"key":"v-1c044960","path":"/3%E6%95%B0%E5%AD%A6/7cda/level3/2_5%E7%89%B9%E5%BE%81%E8%BD%AC%E6%8D%A2.html","title":"","lang":"zh-CN","frontmatter":{"description":"线性的特征转换 与目标字段无关的转换: PCA，SVD，TSVD,矩阵分解NMF 与目标字段有关的转换: LDA 非线性的特征转换 与目标字段无关的转换: Kernel PCA,t-SNE 与目标字段有关的转换: 神经网络 转换出来的新特征, 不好解释. 如果想要好解释性, 最好做特征选择. PCA Principal component analysis (PCA) is a popular linear dimensionality reductiontechnique.","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/3%E6%95%B0%E5%AD%A6/7cda/level3/2_5%E7%89%B9%E5%BE%81%E8%BD%AC%E6%8D%A2.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:description","content":"线性的特征转换 与目标字段无关的转换: PCA，SVD，TSVD,矩阵分解NMF 与目标字段有关的转换: LDA 非线性的特征转换 与目标字段无关的转换: Kernel PCA,t-SNE 与目标字段有关的转换: 神经网络 转换出来的新特征, 不好解释. 如果想要好解释性, 最好做特征选择. PCA Principal component analysis (PCA) is a popular linear dimensionality reductiontechnique."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-21T12:59:55.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-21T12:59:55.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-21T12:59:55.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"PCA","slug":"pca","link":"#pca","children":[]},{"level":2,"title":"SVD","slug":"svd","link":"#svd","children":[{"level":3,"title":"LSA","slug":"lsa","link":"#lsa","children":[]}]},{"level":2,"title":"线性的特征转换-矩阵分解NMF❓","slug":"线性的特征转换-矩阵分解nmf❓","link":"#线性的特征转换-矩阵分解nmf❓","children":[]},{"level":2,"title":"线性的特征转换-LDA❓","slug":"线性的特征转换-lda❓","link":"#线性的特征转换-lda❓","children":[]},{"level":2,"title":"非线性的特征转换-KernelPCA❓","slug":"非线性的特征转换-kernelpca❓","link":"#非线性的特征转换-kernelpca❓","children":[]},{"level":2,"title":"非线性的特征转换-t-SNE❓","slug":"非线性的特征转换-t-sne❓","link":"#非线性的特征转换-t-sne❓","children":[]},{"level":2,"title":"非线性的特征转换+神经网络❓","slug":"非线性的特征转换-神经网络❓","link":"#非线性的特征转换-神经网络❓","children":[]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]}],"git":{"createdTime":1740142795000,"updatedTime":1740142795000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":3.81,"words":1143},"filePathRelative":"3数学/7cda/level3/2_5特征转换.md","localizedDate":"2025年2月21日","excerpt":"<ol>\\n<li>线性的特征转换\\n<ol>\\n<li>与目标字段无关的转换: PCA，SVD，TSVD,矩阵分解NMF</li>\\n<li>与目标字段有关的转换: LDA</li>\\n</ol>\\n</li>\\n<li>非线性的特征转换\\n<ol>\\n<li>与目标字段无关的转换: Kernel PCA,t-SNE</li>\\n<li>与目标字段有关的转换: 神经网络</li>\\n</ol>\\n</li>\\n</ol>\\n<p>转换出来的新特征, 不好解释. 如果想要好解释性, 最好做特征选择.</p>\\n<h2> PCA</h2>\\n<p>Principal component analysis (PCA) is a popular <code>linear</code> dimensionality reductiontechnique.</p>","copyright":{"author":"王新宇"},"autoDesc":true}');export{e as data};
