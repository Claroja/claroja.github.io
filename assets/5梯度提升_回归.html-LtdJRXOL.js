const t=JSON.parse('{"key":"v-64a4cec2","path":"/1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/3%E6%A0%91%E6%A8%A1%E5%9E%8B/5%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91/5%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87_%E5%9B%9E%E5%BD%92.html","title":"GradientBoost","lang":"zh-CN","frontmatter":{"description":"GradientBoost 最佳实践 Gradient Boost最初会做一个单独的叶子节点，而不是tree或者stump，这个叶子节点随机猜测目标值，第一次预测是平均值 将每个样本实际值，减去预测值，得到每个样本的pseudo residual 然后我们建立一棵树分别预测每个样本的pseudo residual 现在预测值就是最初的平均值加上这棵树的预测值（我们给这棵树的预测值加上一个权重，就是学习速率） 如此循环下去 流程","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/3%E6%A0%91%E6%A8%A1%E5%9E%8B/5%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A0%91/5%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87_%E5%9B%9E%E5%BD%92.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"GradientBoost"}],["meta",{"property":"og:description","content":"GradientBoost 最佳实践 Gradient Boost最初会做一个单独的叶子节点，而不是tree或者stump，这个叶子节点随机猜测目标值，第一次预测是平均值 将每个样本实际值，减去预测值，得到每个样本的pseudo residual 然后我们建立一棵树分别预测每个样本的pseudo residual 现在预测值就是最初的平均值加上这棵树的预测值（我们给这棵树的预测值加上一个权重，就是学习速率） 如此循环下去 流程"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://claroja.github.io/"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-25T10:34:16.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"GradientBoost"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-25T10:34:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"GradientBoost\\",\\"image\\":[\\"https://claroja.github.io/\\"],\\"dateModified\\":\\"2025-02-25T10:34:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"最佳实践","slug":"最佳实践","link":"#最佳实践","children":[]},{"level":2,"title":"流程","slug":"流程","link":"#流程","children":[]},{"level":2,"title":"数据集","slug":"数据集","link":"#数据集","children":[]},{"level":2,"title":"简介","slug":"简介","link":"#简介","children":[]},{"level":2,"title":"流程","slug":"流程-1","link":"#流程-1","children":[]},{"level":2,"title":"参考","slug":"参考","link":"#参考","children":[]}],"git":{"createdTime":1740478432000,"updatedTime":1740479656000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":2}]},"readingTime":{"minutes":4.09,"words":1226},"filePathRelative":"1机器学习/1算法原理/3树模型/5梯度提升树/5梯度提升_回归.md","localizedDate":"2025年2月25日","excerpt":"<h1> GradientBoost</h1>\\n<h2> 最佳实践</h2>\\n<ol>\\n<li>Gradient Boost最初会做一个单独的叶子节点，而不是tree或者stump，这个叶子节点随机猜测目标值，第一次预测是平均值</li>\\n<li>将每个样本实际值，减去预测值，得到每个样本的pseudo residual</li>\\n<li>然后我们建立一棵树分别预测每个样本的pseudo residual</li>\\n<li>现在预测值就是最初的平均值加上这棵树的预测值（我们给这棵树的预测值加上一个权重，就是学习速率）</li>\\n<li>如此循环下去</li>\\n</ol>\\n<h2> 流程</h2>","copyright":{"author":"王新宇"},"autoDesc":true}');export{t as data};
