import{_ as n}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as s,c as a,a as t}from"./app-9tftCahk.js";const e={},p=t(`<p>决策树是无参(non-parametric)的监督学习方法. 优点:</p><ol><li>可解释, 可视化, 易理解</li><li>需要较少的数据准备. 其他的算法需要标准化(normalization), 热编码(one-hot, dummy), 去除缺失值. 一些树可以直接处理缺失值.</li><li>The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.</li><li>支持数值型(numerical)和分类型(categorical)数据. 但是目前scikit-learn尚未支持分类数据.</li><li>可以处理多输出问题(multi-output)</li><li>白盒模型,可解释, 可视话, 易理解</li></ol><p>缺点:</p><ol><li>容易过拟合, 可以通过设置超参控制.</li><li>方差大的数据, 或者异常值敏感. 可以通过组合树, 如随机森林解决.</li><li>决策树的预测是非连续型</li><li>可以局部最优, 但不能保证全局最优. 可以通过集成学习解决.</li><li>要做数据平衡.</li></ol><h2 id="api" tabindex="-1"><a class="header-anchor" href="#api" aria-hidden="true">#</a> API</h2><h3 id="构造参数" tabindex="-1"><a class="header-anchor" href="#构造参数" aria-hidden="true">#</a> 构造参数</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier
DecisionTreeClassifier<span class="token punctuation">(</span>
    <span class="token operator">*</span><span class="token punctuation">,</span> 
    criterion<span class="token operator">=</span><span class="token string">&#39;gini&#39;</span><span class="token punctuation">,</span>               <span class="token comment"># 特征分裂的标准, {“gini”, “entropy”, “log_loss”}</span>
    splitter<span class="token operator">=</span><span class="token string">&#39;best&#39;</span><span class="token punctuation">,</span>                <span class="token comment"># 最优的分裂的策略, {“best”, “random”}, best表示在所有特征上递归，适用于数据集较小的时候，random表示随机选择一部分特征进行递归，适用于数据集较大的时候</span>
    max_depth<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>                 <span class="token comment"># 树的深度, 如果为None, 叶节点将趋向于纯净(只有单一变量). 该参量受min_samples_split参数影响</span>
    min_samples_split<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>            <span class="token comment"># 子数据集再切分需要的最小样本量，默认是2，如果子数据样本量小于2时，则不再进行下一步切分。如果数据量较小，使用默认值就可，如果数据量较大，为降低计算量，应该把这个值增大，即限制子数据集的切分次数。</span>
    min_samples_leaf<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>             <span class="token comment"># 叶节点（子数据集）最小样本数，如果子数据集中的样本数小于这个值，那么该叶节点和其兄弟节点都会被剪枝（去掉）</span>
    min_weight_fraction_leaf<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>   <span class="token comment"># 如果我们设置 min_weight_fraction_leaf 为0.1，这意味着每个叶节点在所有输入样本中的权重总和至少要达到10%</span>
    max_features<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>              <span class="token comment"># 每次选取多少个特征决定最优分裂, int, float, auto(所有点特征数量的开方), sqrt(和auto相同), log2(所有特征数的对数), None(所有特征数)</span>
    random_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>              <span class="token comment"># 随机种子</span>
    max_leaf_nodes<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>            <span class="token comment"># 最大叶子节点数</span>
    min_impurity_decrease<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>      <span class="token comment"># 这个值限制了决策树的增长，如果某节点的不纯度(基尼系数，信息增益，均方差，绝对差)小于这个阈值则该节点不再生成子节点。即为叶子节点 。</span>
    class_weight<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>              <span class="token comment"># 指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多导致训练的决策树过于偏向这些类别。这里可以自己指定各个样本的权重，如果使用“balanced”，则算法会自己计算权重，样本量少的类别所对应的样本权重会高。</span>
    ccp_alpha<span class="token operator">=</span><span class="token number">0.0</span>                   <span class="token comment"># Minimal Cost-Complexity Pruning的参数</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol><li>max_features每次分裂所选择的特征数, 比如当max_features=10时, 你的数据50个特征, 第一次分裂随机选择10个特征, 从这个10个特整理选1个最佳的分裂特征. 第二次分裂, 再选择10个, 依次类推.</li><li>splitter=&#39;best&#39;, 选择最佳分裂特征后, best是指选择该特征的最佳分裂点, random是随机选择该特征的分裂点</li></ol><p>参考: https://datascience.stackexchange.com/questions/41417/how-max-features-parameter-works-in-decisiontreeclassifier https://datascience.stackexchange.com/questions/115359/splitter-in-decision-trees-in-sklearn-implementation</p><h3 id="属性" tabindex="-1"><a class="header-anchor" href="#属性" aria-hidden="true">#</a> 属性</h3><ol><li>classes_: 分类模型的类别，如array([0, 1, 2])</li><li>feature_importances_: 特征重要性，以列表的形式输出每个特征的重要性</li><li>max_features_:最大特征数</li><li>n_classes_:类别数，与classes_对应，classes_输出具体的类别</li><li>n_features_:特征数，当数据量小时，一般max_features和n_features_相等</li><li>n_outputs_:输出结果数</li><li>tree_:输出整个决策树,用于生成决策树的可视化</li></ol><h3 id="方法" tabindex="-1"><a class="header-anchor" href="#方法" aria-hidden="true">#</a> 方法</h3><ol><li>decision_path(X):返回X的决策路径</li><li>fit(X, y):在数据集(X,y)上使用决策树模型</li><li>get_params([deep]):获取模型的参数</li><li>predict(X):预测数据值X的标签</li><li>predict_log_proba(X):返回每个类别的概率值的对数</li><li>predict_proba(X):返回每个类别的概率值（有几类就返回几列值）</li><li>score(X,y):返回给定测试集和对应标签的平均准确率</li></ol><h2 id="相同数据-相同参数-结果不同的原因" tabindex="-1"><a class="header-anchor" href="#相同数据-相同参数-结果不同的原因" aria-hidden="true">#</a> 相同数据, 相同参数, 结果不同的原因</h2><p>以下代码, 相同的数据, 相同的参数, 每次结果不同. 而设置了random_state后就会一致.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV

data_all <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>
    <span class="token string">&#39;./data/test/titanic.csv&#39;</span><span class="token punctuation">,</span> 
    usecols<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&#39;Survived&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Pclass&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Age&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;SibSp&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Parch&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Fare&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Sex&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Embarked&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

data_all <span class="token operator">=</span> data_all<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span>

data_all <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>data_all<span class="token punctuation">,</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_all<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">&#39;Sex&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Embarked&#39;</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">&quot;inner&quot;</span><span class="token punctuation">,</span> left_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> right_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
data_all <span class="token operator">=</span> data_all<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">&#39;Sex&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;Embarked&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

data_y <span class="token operator">=</span> data_all<span class="token punctuation">[</span><span class="token string">&#39;Survived&#39;</span><span class="token punctuation">]</span>
data_x <span class="token operator">=</span> data_all<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">&#39;Survived&#39;</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>data_x<span class="token punctuation">,</span> data_y<span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span>

params_default <span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token string">&#39;criterion&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;gini&#39;</span><span class="token punctuation">,</span>
    <span class="token string">&#39;splitter&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;best&#39;</span><span class="token punctuation">,</span>
    <span class="token string">&#39;max_depth&#39;</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token string">&#39;max_features&#39;</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token comment"># &#39;random_state&#39;: 10</span>
<span class="token punctuation">}</span>

clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span><span class="token operator">**</span>params_default<span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>每次决策树分叉时，所有的特征都是随机排序的，随机种子就是random_state 如果你的max_features小于你总特征数n_features，那么每个分叉必须采样，随机性很大 即使你的max_features = n_features，表现相同的分叉还是会选第一个，所以依然有随机性 sklearn的算法大多有random_state，如果需要复盘或是需要模型稳定不变必须设置</p><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考" aria-hidden="true">#</a> 参考</h2><ol><li>https://scikit-learn.org/stable/modules/tree.html#complexity</li><li>https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier</li><li>https://datagy.io/sklearn-decision-tree-classifier/</li><li>https://scikit-learn.org/stable/modules/tree.html</li><li>https://www.zhihu.com/tardis/bd/art/339380585</li><li>https://www.zhihu.com/question/54370722?sort=created</li><li>https://zhuanlan.zhihu.com/p/39780305</li></ol>`,19),o=[p];function i(l,c){return s(),a("div",null,o)}const d=n(e,[["render",i],["__file","2_5_2决策树实践_scikitlearn_模型.html.vue"]]);export{d as default};
