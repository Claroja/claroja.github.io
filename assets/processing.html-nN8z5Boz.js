import{_ as t}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as e,c as p,e as a,a as s,b as n}from"./app-A10JnHE0.js";const l={},c=a('<h1 id="processing" tabindex="-1"><a class="header-anchor" href="#processing" aria-hidden="true">#</a> processing</h1><p>原始数据处理:</p><ol><li>分清哪些数据是连续的, 哪些是离散的</li><li>缺失值处理</li><li>连续的数值特征进行标准化, 均值为0, 方差为1.</li><li>对离散变量进行one-hot编码</li><li>将需要转换为离散数据的连续型数据进行二值化</li><li>防止过拟合, 对数据进行正则化</li><li>在对数据探索后, 返现效果不加, 可以使用多项式方法, 寻找线性关系</li></ol><h2 id="" tabindex="-1"><a class="header-anchor" href="#" aria-hidden="true">#</a></h2><h3 id="_1-standardization-标准化" tabindex="-1"><a class="header-anchor" href="#_1-standardization-标准化" aria-hidden="true">#</a> 1. Standardization(标准化)</h3><p>将特征数据调整为标准正泰分布, 也叫高斯分布, 使得数据的均值为0, 方差为1.</p>',6),o=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"z"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",null,"−"),s("mi",null,"μ"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("mi",null,"s")]),s("annotation",{encoding:"application/x-tex"}," z = (x - \\mu) / s ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"μ"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/"),s("span",{class:"mord mathnormal"},"s")])])])])],-1),i=a(`<p>标准化的原因在于如果有些特征的方差过大, 会使得收敛过程放慢. 另外比如RBF和SVM算法都假设所有的特征的均值为0, 方差为1.</p><p>preprocessing这个模块提供了一个实用类StandarScaler，它可以在训练数据集上做了标准转换操作之后，把相同的转换应用到测试训练集中。 这是相当好的一个功能。可以对训练数据，测试数据应用相同的转换，以后有新的数据进来也可以直接调用，不用再重新把数据放在一起再计算一次了。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token comment">## 创建一组特征数据，每一行表示一个样本，每一列表示一个特征</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">## 另外，StandardScaler()中可以传入两个参数：with_mean,with_std. 默认情况下都是true,但也可以自定义成false.即不要均值中心化或者不要方差规模化为1.</span>
<span class="token comment">## 调用fit方法，根据已有的训练数据创建一个标准化的转换器</span>
scaler <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment">## 进行转换</span>
scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment">## array([[-1.22474487, -1.22474487,  0.70710678],</span>
<span class="token comment">##        [ 0.        ,  0.        , -1.41421356],</span>
<span class="token comment">##        [ 1.22474487,  1.22474487,  0.70710678]])</span>
<span class="token comment">## 现在又来了一组新的样本，也想得到相同的转换</span>
new_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>new_x<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="尺度" tabindex="-1"><a class="header-anchor" href="#尺度" aria-hidden="true">#</a> 尺度</h3><p>如果对稀疏数据进行去均值的中心化就会破坏稀疏的数据结构。MaxAbsScaler 和 maxabs_scale这两个方法是专门为稀疏数据的规模化所设计的。 如果你的数据有许多异常值，那么使用数据的均值与方差去做标准化就不行了。 在这里，你可以使用robust_scale 和 RobustScaler这两个方法。它会根据中位数或者四分位数去中心化数据。</p><h4 id="minmaxscaler-0-1-标准化" tabindex="-1"><a class="header-anchor" href="#minmaxscaler-0-1-标准化" aria-hidden="true">#</a> MinMaxScaler [0,1]标准化</h4><p>将特征分布限定在[0,1]区间内, 最大值为1. 之所以需要将特征规模化到一定的[0,1]范围内，是为了对付那些标准差相当小的特征并且保留下稀疏数据中的0值。</p><p>X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) X_scaled = X_std * (max - min) + min</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">## MinMaxScaler()</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>data_max_<span class="token punctuation">)</span>
<span class="token comment">## [ 1. 18.]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">## [[0.   0.  ]</span>
<span class="token comment">##  [0.25 0.25]</span>
<span class="token comment">##  [0.5  0.5 ]</span>
<span class="token comment">##  [1.   1.  ]]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">## [[1.5 0. ]]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="maxabsscaler-1-1" tabindex="-1"><a class="header-anchor" href="#maxabsscaler-1-1" aria-hidden="true">#</a> MaxAbsScaler [-1,1]</h4><p>将数据尺度化到[-1,1]之间, 这个方法对均值为0或者稀疏矩阵有意义.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>max_abs_scaler <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>MaxAbsScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train_maxsbs <span class="token operator">=</span> max_abs_scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x_train_maxsbs
<span class="token comment">## array([[ 0.5, -1. ,  1. ],</span>
<span class="token comment">##        [ 1. ,  0. ,  0. ],</span>
<span class="token comment">##        [ 0. ,  1. , -0.5]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-non-linear-transformation" tabindex="-1"><a class="header-anchor" href="#_2-non-linear-transformation" aria-hidden="true">#</a> 2. Non-linear transformation</h2><h2 id="_3-ormalization-规范化" tabindex="-1"><a class="header-anchor" href="#_3-ormalization-规范化" aria-hidden="true">#</a> 3. ormalization(规范化)</h2><p>Normalization is the process of scaling individual samples to have unit norm.是将样本在向量空间模型上的一个转换将范数归一.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment">## X = [[ 1., -1.,  2.],</span>
<span class="token comment">##      [ 2.,  0.,  0.],</span>
<span class="token comment">##      [ 0.,  1., -1.]]</span>
X_normalized <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>X<span class="token punctuation">,</span> norm<span class="token operator">=</span><span class="token string">&#39;l2&#39;</span><span class="token punctuation">)</span>
X_normalized
<span class="token comment">## array([[ 0.40..., -0.40...,  0.81...],</span>
<span class="token comment">##        [ 1.  ...,  0.  ...,  0.  ...],</span>
<span class="token comment">##        [ 0.  ...,  0.70..., -0.70...]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="4"><li>Encoding categorical features(分类特征编码)</li></ol><h3 id="ordinalencoder" tabindex="-1"><a class="header-anchor" href="#ordinalencoder" aria-hidden="true">#</a> OrdinalEncoder</h3><p>将数字化理算变量</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">&#39;male&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;from US&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;uses Safari&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">&#39;female&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;from Europe&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;uses Firefox&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">&#39;female&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;from China&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;uses 360&#39;</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
enc <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>OrdinalEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
enc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment">## array([[1., 2., 2.],</span>
<span class="token comment">##        [0., 1., 1.],</span>
<span class="token comment">##        [0., 0., 0.]])</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="onehotencoder" tabindex="-1"><a class="header-anchor" href="#onehotencoder" aria-hidden="true">#</a> OneHotEncoder</h3><p>one-hot或者称为dummy encoding. OrdinalEncoder离散变量使用integer来表示, 在数据中有有些不妥. 比如[&#39;apple&#39;,&#39;orange&#39;,&#39;banana&#39;]标为[0,1,2]. 那么<code>apple</code>和<code>bannana</code>的距离为2, 大于<code>apple</code>和<code>orange</code>的距离1. 而实际上, 三者两两之间的距离应该是相同的.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">&#39;male&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;from US&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;uses Safari&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">&#39;female&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;from Europe&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;uses Firefox&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">&#39;female&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;from China&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;uses 360&#39;</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
enc <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>OneHotEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

enc<span class="token punctuation">.</span>categories_  <span class="token comment"># 查看编码的分类</span>
<span class="token comment">## [array([&#39;female&#39;, &#39;male&#39;], dtype=object),</span>
<span class="token comment">##  array([&#39;from China&#39;, &#39;from Europe&#39;, &#39;from US&#39;], dtype=object),</span>
<span class="token comment">##  array([&#39;uses 360&#39;, &#39;uses Firefox&#39;, &#39;uses Safari&#39;], dtype=object)]</span>

result <span class="token operator">=</span> enc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># transform转换出来的是稀疏矩阵, 使用toarray转换</span>
<span class="token comment">## array([[0., 1., 0., 0., 1., 0., 0., 1.],</span>
<span class="token comment">##        [1., 0., 0., 1., 0., 0., 1., 0.],</span>
<span class="token comment">##        [1., 0., 1., 0., 0., 1., 0., 0.]])</span>

enc<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>result<span class="token punctuation">)</span>  <span class="token comment"># 反编码</span>
<span class="token comment">## array([[&#39;male&#39;, &#39;from US&#39;, &#39;uses Safari&#39;],</span>
<span class="token comment">##        [&#39;female&#39;, &#39;from Europe&#39;, &#39;uses Firefox&#39;],</span>
<span class="token comment">##        [&#39;female&#39;, &#39;from China&#39;, &#39;uses 360&#39;]], dtype=object)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>另外<code>fit(X).transform(X)</code>可以简写为<code>fit_transform(X)</code>, 既:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>result <span class="token operator">=</span>preprocessing<span class="token punctuation">.</span>OneHotEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="discretization-离散化" tabindex="-1"><a class="header-anchor" href="#discretization-离散化" aria-hidden="true">#</a> Discretization(离散化)</h2><p>将连续型数据转换为离散数据.</p><h3 id="kbinsdiscretizer" tabindex="-1"><a class="header-anchor" href="#kbinsdiscretizer" aria-hidden="true">#</a> KBinsDiscretizer</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">,</span> <span class="token number">15</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span>  <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">6.</span><span class="token punctuation">,</span> <span class="token number">14</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span>  <span class="token number">6.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">11</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
est <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>KBinsDiscretizer<span class="token punctuation">(</span>n_bins<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> encode<span class="token operator">=</span><span class="token string">&#39;ordinal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
est<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment">## array([[0., 1., 1.],</span>
<span class="token comment">##        [1., 1., 1.],</span>
<span class="token comment">##        [2., 0., 0.]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,29),r=s("p",null,[n("feature 1: "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"["),s("mo",null,"−"),s("mi",{mathvariant:"normal"},"∞"),s("mo",{separator:"true"},","),s("mo",null,"−"),s("mn",null,"1"),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("mo",{stretchy:"false"},"["),s("mo",null,"−"),s("mn",null,"1"),s("mo",{separator:"true"},","),s("mn",null,"2"),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("mo",{stretchy:"false"},"["),s("mn",null,"2"),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"∞"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"{[-\\infty, -1), [-1, 2), [2, \\infty)}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mopen"},"["),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"∞"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"2"),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"2"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"∞"),s("span",{class:"mclose"},")")])])])]),n(" feature 2: "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"["),s("mo",null,"−"),s("mi",{mathvariant:"normal"},"∞"),s("mo",{separator:"true"},","),s("mn",null,"5"),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("mo",{stretchy:"false"},"["),s("mn",null,"5"),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"∞"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"{[-\\infty, 5), [5, \\infty)}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mopen"},"["),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"∞"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"5"),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"5"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"∞"),s("span",{class:"mclose"},")")])])])]),n(" feature 3: "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"["),s("mo",null,"−"),s("mi",{mathvariant:"normal"},"∞"),s("mo",{separator:"true"},","),s("mn",null,"14"),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("mo",{stretchy:"false"},"["),s("mn",null,"14"),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"∞"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"{[-\\infty, 14), [14, \\infty)}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mopen"},"["),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"∞"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"14"),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"14"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"∞"),s("span",{class:"mclose"},")")])])])])],-1),u=a(`<p>默认是使用<code>one-hot</code>编码, 可以通过encode来指定为<code>ordinal</code>, 比如学生的成绩劣,良,优是逐级递升的, 则使用<code>ordinal</code>更好.</p><h3 id="binarization" tabindex="-1"><a class="header-anchor" href="#binarization" aria-hidden="true">#</a> binarization</h3><p>Feature binarization is the process of thresholding numerical features to get boolean values.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
     <span class="token punctuation">[</span> <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
     <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
binarizer <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>Binarizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>  <span class="token comment"># fit does nothing</span>
binarizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
<span class="token comment">## array([[1., 0., 1.],</span>
<span class="token comment">##        [1., 0., 0.],</span>
<span class="token comment">##        [0., 1., 0.]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="缺失值处理" tabindex="-1"><a class="header-anchor" href="#缺失值处理" aria-hidden="true">#</a> 缺失值处理</h2><p>https://scikit-learn.org/stable/modules/impute.html#impute</p><h2 id="polynomial-features-多项式特征" tabindex="-1"><a class="header-anchor" href="#polynomial-features-多项式特征" aria-hidden="true">#</a> polynomial features(多项式特征)</h2><h3 id="polynomialfeatures" tabindex="-1"><a class="header-anchor" href="#polynomialfeatures" aria-hidden="true">#</a> PolynomialFeatures</h3>`,8),m=s("p",null,[n("线性的特征并不能做出美的模型，于是我们会去尝试非线性。 比如将两个特征 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"X"),s("mn",null,"1")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"X"),s("mn",null,"2")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"(X_1, X_2)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])]),n(",它的平方展开式便转换成5个特征"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"X"),s("mn",null,"1")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"X"),s("mn",null,"2")]),s("mo",{separator:"true"},","),s("msubsup",null,[s("mi",null,"X"),s("mn",null,"1"),s("mn",null,"2")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"X"),s("mn",null,"1")]),s("msub",null,[s("mi",null,"X"),s("mn",null,"2")]),s("mo",{separator:"true"},","),s("msubsup",null,[s("mi",null,"X"),s("mn",null,"2"),s("mn",null,"2")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"(1, X_1, X_2, X_1^2, X_1X_2, X_2^2)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-2.4519em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2481em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-2.4519em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2481em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])]),n(". 代码案例如下：")],-1),d=a(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment">## 自建一组3*2的样本</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment">## 比如将两个特征 (X_1, X_2)，它的平方展开式便转换成5个特征(1, X_1, X_2, X_1^2, X_1X_2, X_2^2). 代码案例如下：</span>
poly <span class="token operator">=</span> PolynomialFeatures<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment">## array([[ 1.,  0.,  1.,  0.,  0.,  1.],</span>
<span class="token comment">##        [ 1.,  2.,  3.,  4.,  6.,  9.],</span>
<span class="token comment">##        [ 1.,  4.,  5., 16., 20., 25.]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="自定义特征转换函数" tabindex="-1"><a class="header-anchor" href="#自定义特征转换函数" aria-hidden="true">#</a> 自定义特征转换函数</h2><p>参考: https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing</p>`,3),k=[c,o,i,r,u,m,d];function h(v,g){return e(),p("div",null,k)}const f=t(l,[["render",h],["__file","processing.html.vue"]]);export{f as default};
