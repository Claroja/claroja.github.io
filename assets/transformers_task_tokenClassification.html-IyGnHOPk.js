const t=JSON.parse('{"key":"v-e3aef98a","path":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/transformers/tutorial/transformers_task_tokenClassification.html","title":"task_tokenClassification","lang":"zh-CN","frontmatter":{"description":"task_tokenClassification token classification tasks: NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) Chunk (Chunking) Grammatically classify the tokens and group them into \\"chunks\\" that go together","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/transformers/tutorial/transformers_task_tokenClassification.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"task_tokenClassification"}],["meta",{"property":"og:description","content":"task_tokenClassification token classification tasks: NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) Chunk (Chunking) Grammatically classify the tokens and group them into \\"chunks\\" that go together"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-11-25T13:46:58.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2023-11-25T13:46:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"task_tokenClassification\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-11-25T13:46:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"NER","slug":"ner","link":"#ner","children":[{"level":3,"title":"数据准备","slug":"数据准备","link":"#数据准备","children":[]}]},{"level":2,"title":"tokenize","slug":"tokenize","link":"#tokenize","children":[]},{"level":2,"title":"Fine-tunning","slug":"fine-tunning","link":"#fine-tunning","children":[]}],"git":{"createdTime":1700920018000,"updatedTime":1700920018000,"contributors":[{"name":"claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":3.21,"words":963},"filePathRelative":"机器学习/transformers/tutorial/transformers_task_tokenClassification.md","localizedDate":"2023年11月25日","excerpt":"<h1> task_tokenClassification</h1>\\n<p>token classification tasks:</p>\\n<ul>\\n<li>NER (Named-entity recognition) Classify the entities in the text (person, organization, location...).</li>\\n<li>POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...)</li>\\n<li>Chunk (Chunking) Grammatically classify the tokens and group them into \\"chunks\\" that go together</li>\\n</ul>","copyright":{"author":"王新宇"},"autoDesc":true}');export{t as data};
