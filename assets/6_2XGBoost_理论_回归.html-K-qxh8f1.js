const e=JSON.parse('{"key":"v-551b9028","path":"/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/3%E6%A0%91%E6%A8%A1%E5%9E%8B/6XGBOOST/6_2XGBoost_%E7%90%86%E8%AE%BA_%E5%9B%9E%E5%BD%92.html","title":"regression","lang":"zh-CN","frontmatter":{"description":"regression 总结 使用Similarity Score计算信息增益 回归 XGBoost(eXtreme Gradient Boosting)是为了解决大, 复杂的数据集而设计的 X轴是药剂量(drug dosages), Y轴是药效(drug effectiveness). 训练XGBoost的第一步是做初始的预测, 这个预测可以是任何值, 默认是0.5, 无论是做分类还是回归. 如下图, 黑实线是初始的预测值, 黑虚线是残差.","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/3%E6%A0%91%E6%A8%A1%E5%9E%8B/6XGBOOST/6_2XGBoost_%E7%90%86%E8%AE%BA_%E5%9B%9E%E5%BD%92.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"regression"}],["meta",{"property":"og:description","content":"regression 总结 使用Similarity Score计算信息增益 回归 XGBoost(eXtreme Gradient Boosting)是为了解决大, 复杂的数据集而设计的 X轴是药剂量(drug dosages), Y轴是药效(drug effectiveness). 训练XGBoost的第一步是做初始的预测, 这个预测可以是任何值, 默认是0.5, 无论是做分类还是回归. 如下图, 黑实线是初始的预测值, 黑虚线是残差."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://claroja.github.io/"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-24T12:46:58.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"regression"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-24T12:46:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"regression\\",\\"image\\":[\\"https://claroja.github.io/\\"],\\"dateModified\\":\\"2025-02-24T12:46:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]},{"level":2,"title":"回归","slug":"回归","link":"#回归","children":[]},{"level":2,"title":"prune","slug":"prune","link":"#prune","children":[]},{"level":2,"title":"lambda","slug":"lambda","link":"#lambda","children":[]},{"level":2,"title":"output","slug":"output","link":"#output","children":[]},{"level":2,"title":"gradient","slug":"gradient","link":"#gradient","children":[]},{"level":2,"title":"参考","slug":"参考","link":"#参考","children":[]}],"git":{"createdTime":1740401218000,"updatedTime":1740401218000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":3.94,"words":1182},"filePathRelative":"2机器学习/1算法原理/3树模型/6XGBOOST/6_2XGBoost_理论_回归.md","localizedDate":"2025年2月24日","excerpt":"<h1> regression</h1>\\n<h2> 总结</h2>\\n<ol>\\n<li>使用Similarity Score计算信息增益</li>\\n</ol>\\n<h2> 回归</h2>\\n<p>XGBoost(eXtreme Gradient Boosting)是为了解决大, 复杂的数据集而设计的</p>\\n<p>X轴是药剂量(drug dosages), Y轴是药效(drug effectiveness).</p>\\n<figure><figcaption></figcaption></figure>\\n<p>训练XGBoost的第一步是做初始的预测, 这个预测可以是任何值, 默认是0.5, 无论是做分类还是回归. 如下图, 黑实线是初始的预测值, 黑虚线是残差.</p>","copyright":{"author":"王新宇"},"autoDesc":true}');export{e as data};
