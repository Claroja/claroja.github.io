import{_ as l}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as e,o as p,c as i,b as s,d as a,e as c,a as n}from"./app-nD1Z-e8V.js";const o="/assets/1-dA5CEvAI.png",m="/assets/2-SAYh-LZu.png",r="/assets/3-bEgg2AHr.png",u="/assets/4-xMBEfGKv.png",h={},d=s("h1",{id:"deepwide",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#deepwide","aria-hidden":"true"},"#"),a(" DeepWide")],-1),g=s("p",null,"Google的应用商店团队Google Play于2016年提出的Wide&Deep模型. Wide&Deep模型正如其名，分别包含了Wide部分和Deep部分。其中Wide部分的作用是让模型具有较强的“记忆能力”(memorization)；而Deep部分的作用是让模型具有“泛化能力”(generalization)。",-1),k=s("p",null,"假设一个点餐的APP, 用户只需要输入它想要的某种食物(query)，点餐app就可以预测出用户最喜欢的食物(item)。如果用户下单了app推荐的食物，那么得分为1，否则为0。",-1),v=s("h2",{id:"wide",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#wide","aria-hidden":"true"},"#"),a(" Wide")],-1),y=s("p",null,[a("首先使用Wide模型来处理这个问题, 这个模型预测一个消费概率"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"c"),s("mi",null,"o"),s("mi",null,"n"),s("mi",null,"s"),s("mi",null,"u"),s("mi",null,"m"),s("mi",null,"p"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"q"),s("mi",null,"u"),s("mi",null,"e"),s("mi",null,"r"),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mi",null,"i"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"m"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"P(consumption|query, item)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"co"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mord mathnormal"},"pt"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"ery"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mclose"},")")])])]),a(", 即对于一个特定的query和推荐的item，它被消费的概率有多大？点餐APP会将概率最大的(query, item)组合推荐给客户.")],-1),b=n('<p>举个例子, P(consumption|query=&#39;fried chicken&#39;, item=&#39;chicken and waffles&#39;)的概率很高, 而P(consumption|query=&quot;fried chicken&quot;, item=&quot;chicken fried rice&quot;)的概率很低, 说明当用户输入fried chicken, 更想获得的是chicken and waffles, 而不是chicken fried rice.</p><p>Wide模型记录了用户的偏好.</p><figure><img src="'+o+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><h2 id="deep" tabindex="-1"><a class="header-anchor" href="#deep" aria-hidden="true">#</a> Deep</h2><p>过了一段时间，用户对app的推荐内容感到疲倦，他们希望app能够推荐一些符合他们口味，但同时又能带来新鲜感的食物。因此我们选择Deep模型来解决这个问题，Deep模型会对每个query和item都生成低维的稠密embedding向量，并且在embedding空间中来查找彼此比较接近的ietm。举个例子，你会发现搜索炸鸡的用户一般也不会介意再吃个汉堡。下图展示了Deep模型示意图，可以看到在Embedding空间中，炸鸡和汉堡彼此距离比较近。</p><figure><img src="'+m+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><h2 id="deep-wide" tabindex="-1"><a class="header-anchor" href="#deep-wide" aria-hidden="true">#</a> Deep &amp; Wide</h2><p>但是Deep模型也有它自身的问题，就是泛化过度，即给用户推荐了不太相关的物品。通过查询历史数据，我们发现实际上存在两种不同的query-item关系。</p><ol><li>精准查询，用户输入了非常精准的食物描述，比如冰脱脂牛奶拿铁咖啡(iced decaf latte with nonfat milk)，我们不能因为它与热全脂拉铁咖啡(hot latte with whole milk)在Embedding空间中比较相近就推荐给用户。</li><li>宽泛查询，比如用户输入了类似海鲜(seafood)或者意大利食物(italian food)这样的关键字，根据这种具有宽泛意义的关键词可以找到非常多相关的item。</li></ol><p>了解到了这些问题之后，一个很自然的想法就是将Wide和Deep模型结合起来使用，如下图：</p><figure><img src="'+r+'" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><p>对于两个稀疏特征query=&quot;fried chicken&quot; 以及 item=&quot;chicken fried rice&quot;，我们同时丢入Wide模型(左边)和Deep模型(右边)进行训练。这样模型就兼具了记忆和泛化的能力，从而可以达到更好的推荐效果。</p><h2 id="公式描述" tabindex="-1"><a class="header-anchor" href="#公式描述" aria-hidden="true">#</a> 公式描述</h2><h3 id="wide-1" tabindex="-1"><a class="header-anchor" href="#wide-1" aria-hidden="true">#</a> wide</h3><p>这个公式在LaTeX语法中的描述如下：</p>',15),_=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("msup",null,[s("mi",null,"w"),s("mi",null,"T")]),s("mo",{stretchy:"false"},"["),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"]"),s("mo",null,"+"),s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"}," y = w^T [x, \\phi(x)] + b ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1413em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])]),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")]"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])])])],-1),f=s("p",null,"其中:",-1),x=s("ol",null,[s("li",null,[s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])]),a("表示原始特征")])]),s("li",null,[s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\phi(x)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),a("表示叉乘特征.")]),s("p",null,"叉乘特征是通过特定的变换函数对特征进行组合得来的，其中论文使用的是交叉积变换函数，其定义如下："),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"ϕ"),s("mi",null,"k")]),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("munderover",null,[s("mo",null,"∏"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"d")]),s("msubsup",null,[s("mi",null,"x"),s("mi",null,"i"),s("msub",null,[s("mi",null,"c"),s("mrow",null,[s("mi",null,"k"),s("mi",null,"i")])])]),s("mspace",{width:"1em"}),s("msub",null,[s("mi",null,"c"),s("mrow",null,[s("mi",null,"k"),s("mi",null,"i")])]),s("mo",null,"∈"),s("mo",{stretchy:"false"},"{"),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mn",null,"1"),s("mo",{stretchy:"false"},"}")]),s("annotation",{encoding:"application/x-tex"}," \\phi_k(x) = \\prod_{i = 1}^{d} x_i^{c_{ki}} \\quad c_{ki} \\in \\{0, 1\\} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.1138em","vertical-align":"-1.2777em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8361em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∏")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"d")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7521em"}},[s("span",{style:{top:"-2.4231em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])]),s("span",{style:{top:"-3.1507em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"c"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3448em"}},[s("span",{style:{top:"-2.3488em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ki")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1512em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2769em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"1em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"c"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ki")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∈"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"{"),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},"}")])])])])]),s("p",null,[a("其中, "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"c"),s("mrow",null,[s("mi",null,"k"),s("mi",null,"i")])])]),s("annotation",{encoding:"application/x-tex"},"c_{ki}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"c"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ki")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("是布尔变量, 当第"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"i")]),s("annotation",{encoding:"application/x-tex"},"i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6595em"}}),s("span",{class:"mord mathnormal"},"i")])])]),a("个特征值属于第"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"k")]),s("annotation",{encoding:"application/x-tex"},"k")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k")])])]),a("个组合特征时，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"c"),s("mrow",null,[s("mi",null,"k"),s("mi",null,"i")])]),s("mo",null,"="),s("mn",null,"1")]),s("annotation",{encoding:"application/x-tex"},"c_{ki}=1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"c"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ki")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"1")])])]),a("，否则为0；"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"x_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("是第"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"i")]),s("annotation",{encoding:"application/x-tex"},"i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6595em"}}),s("span",{class:"mord mathnormal"},"i")])])]),a(`个特征的值。例如，对于组合特征"AND(query='fried chicken', item='chicken fried rice')"来说，只有当query中uery='fried chicken'和item='chicken fried rice'这两个特征都为1的时候，组合特征才为1，否则为0。`)])])],-1),w=s("h3",{id:"deep-1",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#deep-1","aria-hidden":"true"},"#"),a(" deep")],-1),z=s("p",null,"Deep模型其实就是一个前馈神经网络，网络会对一些稀疏特征(如ID类特征)学习一个低维的稠密Embedding向量，维度通常在O(10)~O(100)之间，然后与一些原始稠密特征一起作为网络的输入，依次通过若干隐层进行前向传播，每一个隐层都执行以下计算：",-1),M=s("p",null,"这个公式在LaTeX语法中的表示如下：",-1),L=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"a"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mo",null,"+"),s("mn",null,"1"),s("mo",{stretchy:"false"},")")])]),s("mo",null,"="),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"W"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mo",{stretchy:"false"},")")])]),s("msup",null,[s("mi",null,"a"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mo",{stretchy:"false"},")")])]),s("mo",null,"+"),s("msup",null,[s("mi",null,"b"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mo",{stretchy:"false"},")")])]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," a^{(l+1)} = f (W^{(l)} a^{(l)} + b^{(l)}) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.938em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.188em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.188em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mclose"},")")])])])])],-1),D=s("p",null,[a("其中"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f")]),s("annotation",{encoding:"application/x-tex"},"f")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f")])])]),a("是激活函数，这里选用的是ReLU，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"a"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mo",{stretchy:"false"},")")])]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"b"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mo",{stretchy:"false"},")")])]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"w"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mo",{stretchy:"false"},")")])])]),s("annotation",{encoding:"application/x-tex"},"a^{(l)},b^{(l)},w^{(l)}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0824em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.888em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.888em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.888em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mclose mtight"},")")])])])])])])])])])])]),a("分别是第"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"l")]),s("annotation",{encoding:"application/x-tex"},"l")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a("层的激活值，偏置，以及权重矩阵。")],-1),W=s("h2",{id:"wide-deep联合训练",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#wide-deep联合训练","aria-hidden":"true"},"#"),a(" Wide&Deep联合训练")],-1),q=s("p",null,"论文特意强调了Wide模型和Deep模型是联合(Joint)训练的，与集成(Ensemble)是不同的，集成训练是每个模型单独训练，再将模型结果汇总。因此每个模型都会学的足够好的时候才会进行汇总，故每个模型相对较大。而对于Wide&Deep的联合训练而言，Wide部分只是为了补偿Deep部分缺失的记忆能力，它只需要使用一小部分的叉乘特征，故相对较小。",-1),T=s("p",null,"Wide&Deep模型采用的Logistic Loss函数，模型的预测值定义如下：",-1),E=s("p",null,"这个公式在LaTeX语法中的描述如下：",-1),P=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mi",null,"Y"),s("mo",null,"="),s("mn",null,"1"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("msubsup",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"d"),s("mi",null,"e")]),s("mi",null,"T")]),s("mo",{stretchy:"false"},"["),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"]"),s("mo",null,"+"),s("msubsup",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"d"),s("mi",null,"e"),s("mi",null,"p")]),s("mi",null,"T")]),s("msup",null,[s("mi",null,"a"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"l"),s("mi",null,"f"),s("mo",{stretchy:"false"},")")])]),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," P(Y = 1|x) = \\sigma (w_{ide}^T [x, \\phi(x)] + w_{dep}^T a^{(lf)} + b) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"Y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"1∣"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1413em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-2.453em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"d"),s("span",{class:"mord mathnormal mtight"},"e")])])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.247em"}},[s("span")])])])])]),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")]"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.3211em","vertical-align":"-0.3831em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-2.453em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"d"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"p")])])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3831em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")")])])])])],-1),A=s("p",null,[a("其中Y是二值化的类别标签，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("mo",null,"⋅"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\sigma (\\cdot)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"⋅"),s("span",{class:"mclose"},")")])])]),a("是Sigmoid激活函数，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\phi(x)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),a("是对原始特征"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])]),a("进行交叉积转换后的叉乘特征，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"},"b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])]),a("是偏置值。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"w"),s("mi",null,"i"),s("mi",null,"d"),s("mi",null,"e")])])]),s("annotation",{encoding:"application/x-tex"},"w_{wide}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"d"),s("span",{class:"mord mathnormal mtight"},"e")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("是所有的wide模型的权重，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"d"),s("mi",null,"e"),s("mi",null,"e"),s("mi",null,"p")])])]),s("annotation",{encoding:"application/x-tex"},"w_{deep}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"d"),s("span",{class:"mord mathnormal mtight"},"ee"),s("span",{class:"mord mathnormal mtight"},"p")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])]),a("是应用在最后一层神经元的激活值上的权重矩阵。")],-1),R=n('<p>关于模型训练，论文对Wide部分使用了FTRL算法并且加上了L1正则化，对于Deep部分使用了AdaGrad算法。</p><p>论文使用的Wide&amp;Deep模型结构如下：</p><figure><img src="'+u+`" alt="alt text" tabindex="0" loading="lazy"><figcaption>alt text</figcaption></figure><p>Wide部分的输入仅仅是已安装应用和曝光应用两类特征，其中已安装应用代表用户的历史行为，而曝光应用代表当前的待推荐应用。选择这两类特征的原因是充分发挥Wide部分“记忆能力”强的优势。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token keyword">class</span> <span class="token class-name">Wide</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Wide<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># hand-crafted cross-product features</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>input_dim<span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Deep</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">,</span> hidden_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Deep<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>layer<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> layer <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>hidden_layers<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_layers<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">&#39;deep_dropout&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>dnn<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token comment"># 如果输出层大小是1的话，这里再使用了个ReLU激活函数，可能导致输出全变成0，即造成了梯度消失，导致Loss不收敛</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

<span class="token keyword">class</span> <span class="token class-name">WideDeep</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">,</span> dense_features_cols<span class="token punctuation">,</span> sparse_features_cols<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>WideDeep<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_config <span class="token operator">=</span> config
        <span class="token comment"># 稠密特征的数量</span>
        self<span class="token punctuation">.</span>_num_of_dense_feature <span class="token operator">=</span> dense_features_cols<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 稠密特征</span>
        self<span class="token punctuation">.</span>sparse_features_cols <span class="token operator">=</span> sparse_features_cols

        self<span class="token punctuation">.</span>embedding_layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            <span class="token comment"># 根据稀疏特征的个数创建对应个数的Embedding层，Embedding输入大小是稀疏特征的类别总数，输出稠密向量的维度由config文件配置</span>
            nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings <span class="token operator">=</span> num_feat<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">&#39;embed_dim&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token keyword">for</span> num_feat <span class="token keyword">in</span> self<span class="token punctuation">.</span>sparse_features_cols
        <span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment"># Deep hidden layers</span>
        self<span class="token punctuation">.</span>_deep_hidden_layers <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">&#39;hidden_layers&#39;</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>_deep_hidden_layers<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>_num_of_dense_feature <span class="token operator">+</span> config<span class="token punctuation">[</span><span class="token string">&#39;embed_dim&#39;</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>sparse_features_cols<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>_wide <span class="token operator">=</span> Wide<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_num_of_dense_feature<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_deep <span class="token operator">=</span> Deep<span class="token punctuation">(</span>config<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_deep_hidden_layers<span class="token punctuation">)</span>
        <span class="token comment"># 之前直接将这个final_layer加入到了Deep模块里面，想着反正输出都是1，结果没注意到Deep没经过一个Linear层都会经过Relu激活函数，如果</span>
        <span class="token comment"># 最后输出层大小是1的话，再经过ReLU之后，很可能变为了0，造成梯度消失问题，导致Loss怎么样都降不下来。</span>
        self<span class="token punctuation">.</span>_final_linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_deep_hidden_layers<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 先区分出稀疏特征和稠密特征，这里是按照列来划分的，即所有的行都要进行筛选</span>
        dense_input<span class="token punctuation">,</span> sparse_inputs <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>self<span class="token punctuation">.</span>_num_of_dense_feature<span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>_num_of_dense_feature<span class="token punctuation">:</span><span class="token punctuation">]</span>
        sparse_inputs <span class="token operator">=</span> sparse_inputs<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        sparse_embeds <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>embedding_layers<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>sparse_inputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>sparse_inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        sparse_embeds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>sparse_embeds<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># Deep模块的输入是稠密特征和稀疏特征经过Embedding产生的稠密特征的</span>
        deep_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>sparse_embeds<span class="token punctuation">,</span> dense_input<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        wide_out <span class="token operator">=</span> self<span class="token punctuation">.</span>_wide<span class="token punctuation">(</span>dense_input<span class="token punctuation">)</span>
        deep_out <span class="token operator">=</span> self<span class="token punctuation">.</span>_deep<span class="token punctuation">(</span>deep_input<span class="token punctuation">)</span>
        deep_out <span class="token operator">=</span> self<span class="token punctuation">.</span>_final_linear<span class="token punctuation">(</span>deep_out<span class="token punctuation">)</span>

        <span class="token keyword">assert</span> <span class="token punctuation">(</span>wide_out<span class="token punctuation">.</span>shape <span class="token operator">==</span> deep_out<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>wide_out <span class="token operator">+</span> deep_out<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs

    <span class="token keyword">def</span> <span class="token function">saveModel</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>_config<span class="token punctuation">[</span><span class="token string">&#39;model_name&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">loadModel</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> map_location<span class="token punctuation">)</span><span class="token punctuation">:</span>
        state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_config<span class="token punctuation">[</span><span class="token string">&#39;model_name&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span>map_location<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考" aria-hidden="true">#</a> 参考</h2>`,6),N={href:"https://arxiv.org/pdf/1606.07792",target:"_blank",rel:"noopener noreferrer"},Y=s("li",null,"https://www.jianshu.com/p/eb0cd2cfe75c",-1),B=s("li",null,"https://research.google/blog/wide-amp-deep-learning-better-together-with-tensorflow/",-1),G=s("li",null,"https://github.com/HeartbreakSurvivor/RsAlgorithms/blob/main/Test/widedeep_test.py",-1),I=s("li",null,"https://bbs.huaweicloud.com/blogs/341709",-1),S=s("li",null,"https://www.kaggle.com/code/matanivanov/wide-deep-learning-for-recsys-with-pytorch/notebook",-1),V=s("li",null,"https://jrzaurin.github.io/infinitoml/2021/05/28/pytorch-widedeep_iv.html",-1),U=s("li",null,"https://zhuanlan.zhihu.com/p/53361519",-1),X=s("li",null,"https://blog.csdn.net/google19890102/article/details/78171283",-1),j=s("li",null,"https://ithelp.ithome.com.tw/articles/10225452",-1);function C(F,H){const t=e("ExternalLinkIcon");return p(),i("div",null,[d,g,k,v,y,b,_,f,x,w,z,M,L,D,W,q,T,E,P,A,R,s("ol",null,[s("li",null,[s("a",N,[a("原论文"),c(t)])]),Y,B,G,I,S,V,U,X,j])])}const K=l(h,[["render",C],["__file","1_4DeepWide.html.vue"]]);export{K as default};
