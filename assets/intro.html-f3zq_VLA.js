import{_ as a}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as t,c as r,a as e}from"./app-9tftCahk.js";const i="/assets/1-ZMoYC2OD.png",o="/assets/2-Fy3c8u_B.png",s="/assets/3-_xS4aCB1.png",n={},l=e('<h1 id="intro" tabindex="-1"><a class="header-anchor" href="#intro" aria-hidden="true">#</a> intro</h1><p>Spark Apache Spark是用于大规模数据（large-scala data）处理的统一（unified）分析引擎。最早源于一篇论文: Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing.</p><figure><img src="'+i+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="spark-vs-hadoop" tabindex="-1"><a class="header-anchor" href="#spark-vs-hadoop" aria-hidden="true">#</a> spark vs hadoop</h2><table><thead><tr><th>xxx</th><th>hadoop</th><th>spark</th></tr></thead><tbody><tr><td>类型</td><td>平台:包含计算,存储,调度</td><td>计算</td></tr><tr><td>场景</td><td>磁盘批处理</td><td>内存批处理和流处理</td></tr><tr><td>存储</td><td>MapReduce中间结果存储在HDFS,延迟大</td><td>RDD中间结果存储在内存,延迟小</td></tr><tr><td>运行方式</td><td>Task以进程方式维护，启动慢</td><td>Task以线程方式维护，启动快</td></tr></tbody></table><p>尽管Spark相对于Hadoop而言具有较大优势，但Spark并不能完全替代Hadoop：</p><ul><li>在计算层面，Spark相比较MR（MapReduce）有巨大的性能优势，但至今仍有许多计算工具基于MR构架，比如非常成熟的Hive</li><li>Spark仅做计算，而Hadoop生态圈不仅有计算（MR）也有存储（HDFS）和资源管理调度（YARN），HDFS和YARN仍是许多大数据 体系的核心架构。</li></ul><h2 id="spark-role" tabindex="-1"><a class="header-anchor" href="#spark-role" aria-hidden="true">#</a> spark role</h2><ul><li><strong>Master</strong> 管理集群存储资源。 类比：YARN的ResouceManager</li><li><strong>Worker</strong> 管理单个节点存储资源。 类比：YARN的NodeManager</li><li><strong>Driver</strong> 管理集群计算资源。 类比：YARN的ApplicationMaster</li><li><strong>Executor</strong> 管理单个节点计算资源。 类比：YARN的TASK</li></ul><figure><img src="'+o+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>执行过程：</p><ol><li>创建的 SparkContext 实例会连接到 ClusterManager，根据设置的 CPU 和内存等信息为本次提交分配计算资源，启动 Executor。</li><li>Driver会将用户程序划分为不同的执行阶段Stage，每个执行阶段Stage由一组完全相同Task组成</li><li>Executor在接收到Task后，执行Task，并且将Task的运行状态汇报给Driver，Task分为两种： <ul><li>一种是Shuffle Map Task，它实现数据的重新洗牌，洗牌的结果保存到Executor 所在节点的文件系统中；</li><li>另外一种是Result Task，它负责生成结果数据；</li></ul></li></ol><h2 id="集群模式" tabindex="-1"><a class="header-anchor" href="#集群模式" aria-hidden="true">#</a> 集群模式</h2><ul><li><strong>local</strong> 一个独立进程配合其内部线程来提供完成Spark运行时环境.</li><li><strong>standalone</strong> Standalone模式是Spark自带的一种集群模式，是真实地在多个机器之间搭建Spark集群的环境</li><li><strong>sparkOnYarn</strong> Spark On Yarn的本质 <ul><li>Master角色由YARN的ResourceManager担任.</li><li>Worker角色由YARN的NodeManager担任.</li><li>Driver角色运行在YARN容器内 或 提交任务的客户端进程中</li><li>真正干活的Executor运行在YARN提供的容器内</li></ul></li></ul><h2 id="python-on-spark-原理" tabindex="-1"><a class="header-anchor" href="#python-on-spark-原理" aria-hidden="true">#</a> python on spark 原理</h2><p>PySpark宗旨是在不破坏Spark已有的运行时架构，在Spark架构外层包装一层Python API，借助Py4j实现Python和Java的交互，进而实现通过Python编写Spark应用程序： <img src="'+s+'" alt="" loading="lazy"></p><p>refs:</p>',17),d=[l];function p(h,c){return t(),r("div",null,d)}const k=a(n,[["render",p],["__file","intro.html.vue"]]);export{k as default};
