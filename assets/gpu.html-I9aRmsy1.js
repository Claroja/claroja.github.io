import{_ as n}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as s,e as t}from"./app-O0xqlHfm.js";const p={},e=t(`<h1 id="gpu" tabindex="-1"><a class="header-anchor" href="#gpu" aria-hidden="true">#</a> gpu</h1><h2 id="基础" tabindex="-1"><a class="header-anchor" href="#基础" aria-hidden="true">#</a> 基础</h2><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># GPU是否可用</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 查看有几个GPU, 后续的device名称可以指定第几块GPU, 比如 tensor.to(&quot;cuda:0&quot;)</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dev<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>nvidia-smi <span class="token comment"># 查看GPU的使用</span>
<span class="token function">watch</span> <span class="token parameter variable">-n</span> <span class="token number">10</span> nvidia-smi <span class="token comment"># 定时查看</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="cpu和gpu交换tensor" tabindex="-1"><a class="header-anchor" href="#cpu和gpu交换tensor" aria-hidden="true">#</a> CPU和GPU交换tensor</h2><p><code>pytorch</code>中的<code>Tensor</code>和<code>nn.Module</code>(<code>layer</code>,<code>loss function</code>等)分为<code>CPU</code>和<code>GPU</code>两个版本. 都带有<code>.to()</code>和<code>.cuda()</code>方法.</p><ul><li><code>tensor.cuda()</code>会拷贝<code>CPU</code>上的数据到<code>GPU</code>上, 并返回(之前<code>CPU</code>上的<code>tensor</code>不变).</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> a<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 将CPU上a的数据拷贝到b上, 此时a在CPU上, b在GPU上</span>
a<span class="token punctuation">.</span>is_cuda  <span class="token comment"># False</span>
b<span class="token punctuation">.</span>is_cuda  <span class="token comment"># True</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><code>nn.module.cuda()</code>则会剪切<code>CPU</code>上的数据到<code>GPU</code>上, 并返回自己(之前<code>CPU</code>上的<code>tensor</code>没了), 所以<code>module = module.cuda()</code>和<code>module.cuda()</code>所起的作用是一致的.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
module <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
module<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
module<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>is_cuda <span class="token comment"># True</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>本质是将<code>nn.Module</code>下所有的<code>parameter</code>转移到<code>GPU</code>(<code>parameter</code>本质是<code>tensor</code>).</p><h2 id="转换方法" tabindex="-1"><a class="header-anchor" href="#转换方法" aria-hidden="true">#</a> 转换方法</h2><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
t1 <span class="token operator">=</span> t3<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
t2 <span class="token operator">=</span> t2<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> 

t3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>a<span class="token punctuation">,</span> device<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>t1和t2 都是在CPU创建tensor, 然后将它移动到GPU <code>.to(device)</code>使用起来更方便, 因为可以在开头设定好</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:&lt;id&gt;&quot;</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>然后再任何地方使用, <code>.cuda(&lt;id&gt;)</code>则需要每次都进行验证, 比较麻烦</p><ul><li>t3是直接在GPU上创建tensor, 所以更高效</li></ul><p>如果想把GPU的tensor转换成Numpy的array时, 需要先将tensor转换到CPU中区, 因为Numpy是CPU-only. 另外需要根据是不是需要求导(<code>requires_grad=True</code>), 而选择使用<code>detach()</code></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x  <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span>
x_ <span class="token operator">=</span> x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

y  <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
y_ <span class="token operator">=</span> y<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="应用" tabindex="-1"><a class="header-anchor" href="#应用" aria-hidden="true">#</a> 应用</h2><h3 id="在dataloader取出时-转到gpu" tabindex="-1"><a class="header-anchor" href="#在dataloader取出时-转到gpu" aria-hidden="true">#</a> 在<code>DataLoader</code>取出时, 转到<code>GPU</code></h3><p>这个是主流的方法</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data
Data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Label <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>Data<span class="token punctuation">,</span> Label<span class="token punctuation">)</span>
torch_dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
    dataset<span class="token operator">=</span>torch_dataset<span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    pin_memory<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>torch_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="在创建数据时就转到gpu" tabindex="-1"><a class="header-anchor" href="#在创建数据时就转到gpu" aria-hidden="true">#</a> 在创建数据时就转到<code>GPU</code></h3><p>在这种情况下, <code>DataLoader</code>不能开启多进程, 不建议使用, 因为将batch传给GPU并不是<code>DataLoader</code>的作用.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data

Data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Label <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

Data <span class="token operator">=</span> Data<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
Label <span class="token operator">=</span> Label<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>

torch_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>Data<span class="token punctuation">,</span> Label<span class="token punctuation">)</span>
torch_dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
    dataset<span class="token operator">=</span>torch_dataset<span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>torch_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="多gpu并行运算" tabindex="-1"><a class="header-anchor" href="#多gpu并行运算" aria-hidden="true">#</a> 多GPU并行运算</h3><h4 id="单机多卡" tabindex="-1"><a class="header-anchor" href="#单机多卡" aria-hidden="true">#</a> 单机多卡</h4><p>比如有4块GPU, 其中一个是主GPU, 当其拿到数据后, 假设为16个样本. 那么它会把数据分成4份, 16/4=4, 自己留一份, 其余3分分发到另外3块GPU上进行计算. 等其他GPU计算完成后, 主GPU把结果回收并进行整合. pytorch中主要通过<code>torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)</code>模块, 实现并行计算.</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>module: 需要并行计算的模型</td><td></td></tr><tr><td>device_ids: 可使用的GPU们</td><td></td></tr><tr><td>output_device: 结果输出设备, 默认就是在device_ids[0]，也就是第一块卡上, 因此它的显存会占用的多一些</td><td></td></tr></tbody></table><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token comment">#判断是不是有多个GPU</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>model<span class="token punctuation">,</span>device_ids<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="多机多卡" tabindex="-1"><a class="header-anchor" href="#多机多卡" aria-hidden="true">#</a> 多机多卡</h4><h3 id="sava-与-load" tabindex="-1"><a class="header-anchor" href="#sava-与-load" aria-hidden="true">#</a> sava 与 load</h3><ol><li>GPU上保存, CPU上加载</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span> <span class="token comment"># 保存</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>CPU上保存, GPU上加载</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span> <span class="token comment"># 保存</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>多GPU 使用上述方法会报错:<code>KeyError: ‘unexpected key “module.conv1.weight” in state_dict’</code>, 原因是使用多GPU时, 会使用<code>torch.nn.DataParallel</code>, 所以checkpoint中有module字样 解决方法1:</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment">## 保存checkpoint时不保存module</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>解决方法2:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment">## 创建一个不包含\`module.\`的新OrderedDict</span>
<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
new_state_dict <span class="token operator">=</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> state_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> k<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 去掉 \`module.\`</span>
    new_state_dict<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> v
<span class="token comment">## 加载参数</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>new_state_dict<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>参考: https://stackoverflow.com/questions/53331247/pytorch-0-4-0-there-are-three-ways-to-create-tensors-on-cuda-device-is-there-s https://blog.csdn.net/weixin_39533659/article/details/111173642 https://blog.csdn.net/joyce_peng/article/details/104133594</p>`,42),o=[e];function c(u,l){return a(),s("div",null,o)}const r=n(p,[["render",c],["__file","gpu.html.vue"]]);export{r as default};
