import{_ as s}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as e,c as l,a as n,b as a}from"./app-7knaTE3M.js";const t={},r=n('<h1 id="预测评估及变量选择" tabindex="-1"><a class="header-anchor" href="#预测评估及变量选择" aria-hidden="true">#</a> 预测评估及变量选择</h1><h3 id="拟合精度与预测精度" tabindex="-1"><a class="header-anchor" href="#拟合精度与预测精度" aria-hidden="true">#</a> 拟合精度与预测精度</h3><p>拟合精度: 模型与已知数据的契合度 预测精度: 模型与未知数据的契合度</p><h3 id="过拟合" tabindex="-1"><a class="header-anchor" href="#过拟合" aria-hidden="true">#</a> 过拟合</h3><p>过拟合: 拟合精度很高, 预测精度却很低的现象叫做过拟合</p><h3 id="变量选择的意义" tabindex="-1"><a class="header-anchor" href="#变量选择的意义" aria-hidden="true">#</a> 变量选择的意义</h3><p>解释变量过多是过拟合的常见原因. 删除多余的解释变量有可能提高预测精确度, 而增加多余的解释变量会提高拟合精度.</p><h3 id="泛化误差" tabindex="-1"><a class="header-anchor" href="#泛化误差" aria-hidden="true">#</a> 泛化误差</h3><p>预测值和未知数据之间的误差叫做泛化误差.</p><h3 id="训练集和测试集" tabindex="-1"><a class="header-anchor" href="#训练集和测试集" aria-hidden="true">#</a> 训练集和测试集</h3><p>用来估计参数的数据叫做训练集. 通过评估训练集的拟合程度可以求出拟合精度, 但不能评估泛化误差. 在估计参数时特意保留的一部分已知数据叫做测试集. 使用测试集评估模型进度可以在一定程度上评估泛化误差.</p><h3 id="交叉验证" tabindex="-1"><a class="header-anchor" href="#交叉验证" aria-hidden="true">#</a> 交叉验证</h3><p>基于特定的准则把数据分为训练集和测试集, 针对测试集评价模型预测精度的方法叫做交叉验证法(cross validation, cv). 交叉验证法主要有留出交叉验证(leave-p-out cv)和k折交叉验证(k-fold cv)两种.</p><ol><li>留出交叉验证 从已知数据中取出p个数据作为测试集. 例如, 留2交叉验证就是从已知数据中取出2个数据用来评估预测精度, 将其余数据作为训练集. 通过这种方法计算所有可能的数据组合的预测精度, 得出的结果的均值就是最终的评估值.</li><li>k折交叉验证 把已知数据分为K组, 取其中1组作为测试集. 重复K次, 以预测精度的均值作为最终的评估值</li></ol><p>假设样本容量为100, 当留出交叉验证是留出1个数据, K折交叉验证是分为100组时, 测试数据其实都是1个数据, 因此两种验证方法等价.</p><p>交叉验证的缺点是要反复进行参数估计和精度评估, 计算量巨大.</p><h3 id="赤池信息量准则" tabindex="-1"><a class="header-anchor" href="#赤池信息量准则" aria-hidden="true">#</a> 赤池信息量准则</h3><p>赤池信息量准则(AIC)的数学公式如下:</p>',18),c=a("p",{class:"katex-block"},[a("span",{class:"katex-display"},[a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[a("semantics",null,[a("mrow",null,[a("mi",null,"A"),a("mi",null,"I"),a("mi",null,"C"),a("mo",null,"="),a("mo",null,"−"),a("mn",null,"2"),a("mo",null,"×"),a("mo",{stretchy:"false"},"("),a("mtext",null,"最大对数似然"),a("mo",null,"−"),a("mtext",null,"参与估计的参数个数"),a("mo",{stretchy:"false"},")")]),a("annotation",{encoding:"application/x-tex"}," AIC = -2 \\times (最大对数似然 - 参与估计的参数个数) ")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6833em"}}),a("span",{class:"mord mathnormal"},"A"),a("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),a("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"="),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),a("span",{class:"mord"},"−"),a("span",{class:"mord"},"2"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"×"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),a("span",{class:"mopen"},"("),a("span",{class:"mord cjk_fallback"},"最大对数似然"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),a("span",{class:"mord cjk_fallback"},"参与估计的参数个数"),a("span",{class:"mclose"},")")])])])])],-1),i=a("p",null,"AIC越小, 模型越合适. 对数似然越大, 拟合精度就越高. 但如果过于注重拟合精度, 泛化误差就会变大. 在AIC中, 参数个数为惩罚指标. 解释变量越多, 对数似然越大, 同时惩罚也越严重. AIC可以判断增加的对数似然能否弥补更多的解释变量带来的缺点. 可以使用AIC删除多余的变量. 比起交叉验证法, AIC的一大优势是计算量更小.",-1),h=a("p",null,"参考:",-1),m=[r,c,i,h];function p(d,o){return e(),l("div",null,m)}const g=s(t,[["render",p],["__file","预测评估及变量选择.html.vue"]]);export{g as default};
