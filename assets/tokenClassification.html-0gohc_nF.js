const t=JSON.parse('{"key":"v-c2ba8874","path":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/transformers/tutorial/tokenClassification.html","title":"tokenClassification","lang":"zh-CN","frontmatter":{"description":"tokenClassification token classification tasks: NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) Chunk (Chunking) Grammatically classify the tokens and group them into \\"chunks\\" that go together","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/transformers/tutorial/tokenClassification.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"tokenClassification"}],["meta",{"property":"og:description","content":"tokenClassification token classification tasks: NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) Chunk (Chunking) Grammatically classify the tokens and group them into \\"chunks\\" that go together"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-11-27T13:17:01.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2023-11-27T13:17:01.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"tokenClassification\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-11-27T13:17:01.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"NER","slug":"ner","link":"#ner","children":[{"level":3,"title":"数据准备","slug":"数据准备","link":"#数据准备","children":[]}]},{"level":2,"title":"tokenize","slug":"tokenize","link":"#tokenize","children":[]},{"level":2,"title":"Fine-tunning","slug":"fine-tunning","link":"#fine-tunning","children":[]}],"git":{"createdTime":1701091021000,"updatedTime":1701091021000,"contributors":[{"name":"claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":3.21,"words":963},"filePathRelative":"机器学习/transformers/tutorial/tokenClassification.md","localizedDate":"2023年11月27日","excerpt":"<h1> tokenClassification</h1>\\n<p>token classification tasks:</p>\\n<ul>\\n<li>NER (Named-entity recognition) Classify the entities in the text (person, organization, location...).</li>\\n<li>POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...)</li>\\n<li>Chunk (Chunking) Grammatically classify the tokens and group them into \\"chunks\\" that go together</li>\\n</ul>","copyright":{"author":"王新宇"},"autoDesc":true}');export{t as data};
