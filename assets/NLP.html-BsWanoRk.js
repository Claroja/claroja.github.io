const e=JSON.parse('{"key":"v-3ca1b203","path":"/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/6transformers/tokenizer/NLP.html","title":"NLP","lang":"zh-CN","frontmatter":{"description":"NLP models can only process numbers, so we need to convert the raw text to numbers by using tokenizer. Tokenization Tokenization include three steps, Behind the pipeline","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/6transformers/tokenizer/NLP.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"NLP"}],["meta",{"property":"og:description","content":"NLP models can only process numbers, so we need to convert the raw text to numbers by using tokenizer. Tokenization Tokenization include three steps, Behind the pipeline"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-24T12:46:58.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-24T12:46:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"NLP\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-24T12:46:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"Tokenization","slug":"tokenization","link":"#tokenization","children":[{"level":3,"title":"splitting into tokens","slug":"splitting-into-tokens","link":"#splitting-into-tokens","children":[]},{"level":3,"title":"Mapping token to integer","slug":"mapping-token-to-integer","link":"#mapping-token-to-integer","children":[]},{"level":3,"title":"Adding additional inputs","slug":"adding-additional-inputs","link":"#adding-additional-inputs","children":[]}]},{"level":2,"title":"use tokenizer","slug":"use-tokenizer","link":"#use-tokenizer","children":[{"level":3,"title":"padding","slug":"padding","link":"#padding","children":[]},{"level":3,"title":"truncation","slug":"truncation","link":"#truncation","children":[]},{"level":3,"title":"return","slug":"return","link":"#return","children":[]},{"level":3,"title":"Special tokens","slug":"special-tokens","link":"#special-tokens","children":[]},{"level":3,"title":"loading and saving","slug":"loading-and-saving","link":"#loading-and-saving","children":[]}]},{"level":2,"title":"Notice","slug":"notice","link":"#notice","children":[]}],"git":{"createdTime":1740401218000,"updatedTime":1740401218000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":4.83,"words":1450},"filePathRelative":"2机器学习/3分析工具/6transformers/tokenizer/NLP.md","localizedDate":"2025年2月24日","excerpt":"<h1> NLP</h1>\\n<p>models can only process numbers, so we need to convert the raw text to numbers by using <code>tokenizer</code>.</p>\\n<h2> Tokenization</h2>\\n<p>Tokenization include three steps, <a href=\\"https://huggingface.co/course/chapter2/2?fw=pt\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Behind the pipeline</a></p>","copyright":{"author":"王新宇"},"autoDesc":true}');export{e as data};
