const e=JSON.parse(`{"key":"v-6f8479f1","path":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1_2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B/4_4_2%E8%B6%85%E5%8F%82%E8%B0%83%E4%BC%98_%E5%90%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0.html","title":"","lang":"zh-CN","frontmatter":{"description":"模型参数搜索 Logistic Regression: C: 设置正则参数λ\\\\lambdaλ, C=1λC=\\\\frac{1}{\\\\lambda}C=λ1​ penalty: Regularization term ('l1' or 'l2'). LogisticRegression(C=1000.0, random_state=0) Neural Networks: batch_size: Number of samples per gradient update. epochs: Number of epochs to train the model. optimizer: Optimizer algorithm to use (e.g., 'adam', 'sgd'). learning_rate: Learning rate for the optimizer. Decision Trees: criterion is the function to measure the quality of a split max_depth: Maximum depth of the tree. random_state is the seed used by the random number generator. min_samples_split: Minimum number of samples required to split a node. min_samples_leaf: Minimum number of samples required at each leaf node. DecisionTreeClassifier(criterion=’entropy’, max_depth=3, random_state=0) Random Forest: Parameters from Decision Trees plus: n_estimators: Number of trees in the forest. max_features: Number of features to consider when looking for the best split. Gradient Boosting Machines (GBM): Parameters for decision trees plus n_estimators: Number of boosting stages. learning_rate: Learning rate shrinks the contribution of each tree. subsample: Fraction of samples used for fitting the individual base learners. K-Nearest Neighbors (KNN): n_neighbors: Number of neighbors to consider. p Minkowski power parameter p = 1, Manhattan distance p = 2, Euclidean distance metric: 举例矩阵 KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski') Support Vector Machines (SVM): kernel: Specifies the kernel type to be used. linear classification, kernel = linear non-linear classification, kernel = rbf or sigmoid. C: Penalty parameter of the error term. controls the trade-off between smooth decision boundaries and classifying training points correctly. random_state is a pseudo-random number generator used to ensure reproducibility of results across different runs. SVC(kernel='linear', C=1.0, random_state=0) Naive Bayes: No specific hyperparameters for cross-validation in the typical sense, though you might cross-validate smoothing parameters for certain variants like Gaussian Naive Bayes.","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1_2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B/4_4_2%E8%B6%85%E5%8F%82%E8%B0%83%E4%BC%98_%E5%90%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:description","content":"模型参数搜索 Logistic Regression: C: 设置正则参数λ\\\\lambdaλ, C=1λC=\\\\frac{1}{\\\\lambda}C=λ1​ penalty: Regularization term ('l1' or 'l2'). LogisticRegression(C=1000.0, random_state=0) Neural Networks: batch_size: Number of samples per gradient update. epochs: Number of epochs to train the model. optimizer: Optimizer algorithm to use (e.g., 'adam', 'sgd'). learning_rate: Learning rate for the optimizer. Decision Trees: criterion is the function to measure the quality of a split max_depth: Maximum depth of the tree. random_state is the seed used by the random number generator. min_samples_split: Minimum number of samples required to split a node. min_samples_leaf: Minimum number of samples required at each leaf node. DecisionTreeClassifier(criterion=’entropy’, max_depth=3, random_state=0) Random Forest: Parameters from Decision Trees plus: n_estimators: Number of trees in the forest. max_features: Number of features to consider when looking for the best split. Gradient Boosting Machines (GBM): Parameters for decision trees plus n_estimators: Number of boosting stages. learning_rate: Learning rate shrinks the contribution of each tree. subsample: Fraction of samples used for fitting the individual base learners. K-Nearest Neighbors (KNN): n_neighbors: Number of neighbors to consider. p Minkowski power parameter p = 1, Manhattan distance p = 2, Euclidean distance metric: 举例矩阵 KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski') Support Vector Machines (SVM): kernel: Specifies the kernel type to be used. linear classification, kernel = linear non-linear classification, kernel = rbf or sigmoid. C: Penalty parameter of the error term. controls the trade-off between smooth decision boundaries and classifying training points correctly. random_state is a pseudo-random number generator used to ensure reproducibility of results across different runs. SVC(kernel='linear', C=1.0, random_state=0) Naive Bayes: No specific hyperparameters for cross-validation in the typical sense, though you might cross-validate smoothing parameters for certain variants like Gaussian Naive Bayes."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-18T14:02:01.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-18T14:02:01.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-18T14:02:01.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"模型参数搜索","slug":"模型参数搜索","link":"#模型参数搜索","children":[]}],"git":{"createdTime":1739887321000,"updatedTime":1739887321000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":1.15,"words":346},"filePathRelative":"机器学习/1_2机器学习流程/4_4_2超参调优_各模型参数.md","localizedDate":"2025年2月18日","excerpt":"<h2> 模型参数搜索</h2>\\n<ol start=\\"6\\">\\n<li>\\n<p>Logistic Regression:</p>\\n<ol>\\n<li>C: 设置正则参数<span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\\"application/x-tex\\">\\\\lambda</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6944em;\\"></span><span class=\\"mord mathnormal\\">λ</span></span></span></span>, <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>C</mi><mo>=</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac></mrow><annotation encoding=\\"application/x-tex\\">C=\\\\frac{1}{\\\\lambda}</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6833em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.07153em;\\">C</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1.1901em;vertical-align:-0.345em;\\"></span><span class=\\"mord\\"><span class=\\"mopen nulldelimiter\\"></span><span class=\\"mfrac\\"><span class=\\"vlist-t vlist-t2\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.8451em;\\"><span style=\\"top:-2.655em;\\"><span class=\\"pstrut\\" style=\\"height:3em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mathnormal mtight\\">λ</span></span></span></span><span style=\\"top:-3.23em;\\"><span class=\\"pstrut\\" style=\\"height:3em;\\"></span><span class=\\"frac-line\\" style=\\"border-bottom-width:0.04em;\\"></span></span><span style=\\"top:-3.394em;\\"><span class=\\"pstrut\\" style=\\"height:3em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mtight\\">1</span></span></span></span></span><span class=\\"vlist-s\\">​</span></span><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.345em;\\"><span></span></span></span></span></span><span class=\\"mclose nulldelimiter\\"></span></span></span></span></span></li>\\n<li>penalty: Regularization term ('l1' or 'l2').</li>\\n</ol>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code>LogisticRegression<span class=\\"token punctuation\\">(</span>C<span class=\\"token operator\\">=</span><span class=\\"token number\\">1000.0</span><span class=\\"token punctuation\\">,</span> random_state<span class=\\"token operator\\">=</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div></div></div></li>\\n<li>\\n<p>Neural Networks:</p>\\n<ol>\\n<li>batch_size: Number of samples per gradient update.</li>\\n<li>epochs: Number of epochs to train the model.</li>\\n<li>optimizer: Optimizer algorithm to use (e.g., 'adam', 'sgd').</li>\\n<li>learning_rate: Learning rate for the optimizer.</li>\\n</ol>\\n</li>\\n<li>\\n<p>Decision Trees:</p>\\n<ol>\\n<li>criterion is the function to measure the quality of a split</li>\\n<li>max_depth: Maximum depth of the tree.</li>\\n<li>random_state is the seed used by the random number generator.</li>\\n<li>min_samples_split: Minimum number of samples required to split a node.</li>\\n<li>min_samples_leaf: Minimum number of samples required at each leaf node.</li>\\n</ol>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code>DecisionTreeClassifier<span class=\\"token punctuation\\">(</span>criterion<span class=\\"token operator\\">=</span>’entropy’<span class=\\"token punctuation\\">,</span> max_depth<span class=\\"token operator\\">=</span><span class=\\"token number\\">3</span><span class=\\"token punctuation\\">,</span> random_state<span class=\\"token operator\\">=</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div></div></div></li>\\n<li>\\n<p>Random Forest:</p>\\n<ol>\\n<li>Parameters from Decision Trees plus:</li>\\n<li>n_estimators: Number of trees in the forest.</li>\\n<li>max_features: Number of features to consider when looking for the best split.</li>\\n</ol>\\n</li>\\n<li>\\n<p>Gradient Boosting Machines (GBM): Parameters for decision trees plus</p>\\n<ol>\\n<li>n_estimators: Number of boosting stages.</li>\\n<li>learning_rate: Learning rate shrinks the contribution of each tree.</li>\\n<li>subsample: Fraction of samples used for fitting the individual base learners.</li>\\n</ol>\\n</li>\\n<li>\\n<p>K-Nearest Neighbors (KNN):</p>\\n<ol>\\n<li>n_neighbors: Number of neighbors to consider.</li>\\n<li>p Minkowski power parameter\\n<ol>\\n<li>p = 1, Manhattan distance</li>\\n<li>p = 2, Euclidean distance</li>\\n</ol>\\n</li>\\n<li>metric: 举例矩阵</li>\\n</ol>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code>KNeighborsClassifier<span class=\\"token punctuation\\">(</span>n_neighbors<span class=\\"token operator\\">=</span><span class=\\"token number\\">5</span><span class=\\"token punctuation\\">,</span> p<span class=\\"token operator\\">=</span><span class=\\"token number\\">2</span><span class=\\"token punctuation\\">,</span> metric<span class=\\"token operator\\">=</span><span class=\\"token string\\">'minkowski'</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div></div></div></li>\\n<li>\\n<p>Support Vector Machines (SVM):</p>\\n<ol>\\n<li>kernel: Specifies the kernel type to be used.\\n<ol>\\n<li>linear classification, <code>kernel</code> =  <code>linear</code></li>\\n<li>non-linear classification, <code>kernel</code> = <code>rbf</code> or <code>sigmoid</code>.</li>\\n</ol>\\n</li>\\n<li>C: Penalty parameter of the error term.  controls the trade-off between smooth decision boundaries and classifying training points correctly.</li>\\n<li>random_state is a pseudo-random number generator used to ensure reproducibility of results across different runs.</li>\\n</ol>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code>SVC<span class=\\"token punctuation\\">(</span>kernel<span class=\\"token operator\\">=</span><span class=\\"token string\\">'linear'</span><span class=\\"token punctuation\\">,</span> C<span class=\\"token operator\\">=</span><span class=\\"token number\\">1.0</span><span class=\\"token punctuation\\">,</span> random_state<span class=\\"token operator\\">=</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div></div></div></li>\\n<li>\\n<p>Naive Bayes:</p>\\n<p>No specific hyperparameters for cross-validation in the typical sense, though you might cross-validate smoothing parameters for certain variants like Gaussian Naive Bayes.</p>\\n</li>\\n</ol>","copyright":{"author":"王新宇"},"autoDesc":true}`);export{e as data};
