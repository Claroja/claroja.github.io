const t=JSON.parse('{"key":"v-85e36cf2","path":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2_1%E6%A0%91%E6%A8%A1%E5%9E%8B/1%E6%A0%91%E6%A8%A1%E5%9E%8B.html","title":"","lang":"zh-CN","frontmatter":{"description":"scikit-learn使用的是CART树. 类别: 按任务分：分类树（Classificationtree）与回归树（Decisiontree） 按特征选择方法分：ID3决策树算法、C4.5决策树算法、CART决策树算法 时间 模型 任务 树 特征选择 1984 CART 分类、回归 二叉树 基尼系数（Gini）、平方误差（MSE） 1986 ID3 分类 多叉树 信息增益（Information Gain） 1993 C4.5 分类 多叉树 信息增益比（Information Gain Ratio）","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2_1%E6%A0%91%E6%A8%A1%E5%9E%8B/1%E6%A0%91%E6%A8%A1%E5%9E%8B.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:description","content":"scikit-learn使用的是CART树. 类别: 按任务分：分类树（Classificationtree）与回归树（Decisiontree） 按特征选择方法分：ID3决策树算法、C4.5决策树算法、CART决策树算法 时间 模型 任务 树 特征选择 1984 CART 分类、回归 二叉树 基尼系数（Gini）、平方误差（MSE） 1986 ID3 分类 多叉树 信息增益（Information Gain） 1993 C4.5 分类 多叉树 信息增益比（Information Gain Ratio）"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-18T14:02:01.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-18T14:02:01.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-18T14:02:01.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"决策树的专有名词","slug":"决策树的专有名词","link":"#决策树的专有名词","children":[]},{"level":2,"title":"决策树直觉","slug":"决策树直觉","link":"#决策树直觉","children":[]},{"level":2,"title":"最优分裂特征","slug":"最优分裂特征","link":"#最优分裂特征","children":[]},{"level":2,"title":"Splitting in Decision Tree","slug":"splitting-in-decision-tree","link":"#splitting-in-decision-tree","children":[]},{"level":2,"title":"参考","slug":"参考","link":"#参考","children":[]}],"git":{"createdTime":1739887321000,"updatedTime":1739887321000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":2.85,"words":854},"filePathRelative":"机器学习/2_1树模型/1树模型.md","localizedDate":"2025年2月18日","excerpt":"<p><code>scikit-learn</code>使用的是CART树.</p>\\n<p>类别:</p>\\n<ol>\\n<li>按任务分：分类树（Classificationtree）与回归树（Decisiontree）</li>\\n<li>按特征选择方法分：ID3决策树算法、C4.5决策树算法、CART决策树算法</li>\\n</ol>\\n<table>\\n<thead>\\n<tr>\\n<th>时间</th>\\n<th>模型</th>\\n<th>任务</th>\\n<th>树</th>\\n<th>特征选择</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>1984</td>\\n<td>CART</td>\\n<td>分类、回归</td>\\n<td>二叉树</td>\\n<td>基尼系数（Gini）、平方误差（MSE）</td>\\n</tr>\\n<tr>\\n<td>1986</td>\\n<td>ID3</td>\\n<td>分类</td>\\n<td>多叉树</td>\\n<td>信息增益（Information Gain）</td>\\n</tr>\\n<tr>\\n<td>1993</td>\\n<td>C4.5</td>\\n<td>分类</td>\\n<td>多叉树</td>\\n<td>信息增益比（Information Gain Ratio）</td>\\n</tr>\\n</tbody>\\n</table>","copyright":{"author":"王新宇"},"autoDesc":true}');export{t as data};
