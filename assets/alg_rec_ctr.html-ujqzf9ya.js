const e=JSON.parse('{"key":"v-2632e608","path":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/alg_rec_ctr.html","title":"rec_ctr","lang":"zh-CN","frontmatter":{"description":"rec_ctr Click Through Rate(CTR)指的是推送给某个顾客的商品是否会被点击。最简单的方法就是逻辑回归(LR)，LR使用了Sigmoid变换将函数值映射到0~1区间，就是CTR的预估值。LR优点是简单，计算资源消耗较少，但是学习能力十分有限。需要大量的特征工程来增加模型的学习能力。因此，如何自动发现有效的特征、特征组合，弥补人工经验不足，缩短LR特征实验周期，是亟需解决的问题。 建树采用GBDT而非RF：RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/alg_rec_ctr.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"rec_ctr"}],["meta",{"property":"og:description","content":"rec_ctr Click Through Rate(CTR)指的是推送给某个顾客的商品是否会被点击。最简单的方法就是逻辑回归(LR)，LR使用了Sigmoid变换将函数值映射到0~1区间，就是CTR的预估值。LR优点是简单，计算资源消耗较少，但是学习能力十分有限。需要大量的特征工程来增加模型的学习能力。因此，如何自动发现有效的特征、特征组合，弥补人工经验不足，缩短LR特征实验周期，是亟需解决的问题。 建树采用GBDT而非RF：RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-11-25T13:46:58.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2023-11-25T13:46:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"rec_ctr\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-11-25T13:46:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"GBDT","slug":"gbdt","link":"#gbdt","children":[{"level":3,"title":"导入依赖","slug":"导入依赖","link":"#导入依赖","children":[]},{"level":3,"title":"数据集及预处理","slug":"数据集及预处理","link":"#数据集及预处理","children":[]},{"level":3,"title":"模型训练","slug":"模型训练","link":"#模型训练","children":[]}]},{"level":2,"title":"LR","slug":"lr","link":"#lr","children":[{"level":3,"title":"数据处理","slug":"数据处理","link":"#数据处理","children":[]},{"level":3,"title":"模型训练","slug":"模型训练-1","link":"#模型训练-1","children":[]},{"level":3,"title":"评估","slug":"评估","link":"#评估","children":[]}]}],"git":{"createdTime":1700920018000,"updatedTime":1700920018000,"contributors":[{"name":"claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":3.62,"words":1087},"filePathRelative":"机器学习/推荐系统/alg_rec_ctr.md","localizedDate":"2023年11月25日","excerpt":"<h1> rec_ctr</h1>\\n<p>Click Through Rate(CTR)指的是推送给某个顾客的商品是否会被点击。最简单的方法就是逻辑回归(LR)，LR使用了Sigmoid变换将函数值映射到0~1区间，就是CTR的预估值。LR优点是简单，计算资源消耗较少，但是学习能力十分有限。需要大量的特征工程来增加模型的学习能力。因此，如何自动发现有效的特征、特征组合，弥补人工经验不足，缩短LR特征实验周期，是亟需解决的问题。</p>\\n<p>建树采用GBDT而非RF：RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。</p>","copyright":{"author":"王新宇"},"autoDesc":true}');export{e as data};
