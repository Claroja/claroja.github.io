import{_ as o}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as e,o as r,c as h,b as t,d as l,e as a,a as M}from"./app-7knaTE3M.js";const B={},E=M('<p>观测序列就是你确确实实可以看到的句子，如：“更高地举起邓小平理论的伟大旗帜”。而何为状态序列呢？在中文分词中，我们包括一下几种状态：</p><ol><li>B：词语的开头（单词的头一个字），不分词</li><li>M：中间词（即在一个词语的开头和结尾之中），不分词</li><li>E：单词的结尾（即单词的最后一个字），进行分词</li><li>S：单个字，进行分词</li></ol><p>分词以后就是：“更 高 地 举起 邓小平理论 的 伟大 旗帜”，在后方加入状态就是：“更(S) 高(S) 地(S) 举起(BE) 邓小平理论(BMMME) 的(S) 伟大(BE) 旗帜(BE)&quot;，即对应的状态序列就是“SSSBEBMMMESBEBE”</p><p>因为我们语料库中的语句都已经分词完毕了，所以我们既获得了观测序列，又可以获得状态序列。那么只需要用极大似然估计法即可啦。其实就是简单的算得频率=频数/总数。当然，若语料是没有分词的，我们便只有观测序列，这时就要用Baum-Welch算法。</p><ol><li><p>在我们本次分词项目中，状态转移概率矩阵A是这样的：</p><table><thead><tr><th></th><th>B</th><th>M</th><th>E</th><th>S</th></tr></thead><tbody><tr><td>B</td><td>B to B</td><td>B to M</td><td>B to E</td><td>B to S</td></tr><tr><td>M</td><td>M to B</td><td>M to M</td><td>M to E</td><td>M to S</td></tr><tr><td>E</td><td>E to B</td><td>E to M</td><td>E to E</td><td>E to S</td></tr><tr><td>S</td><td>S to B</td><td>S to M</td><td>S to E</td><td>S to S</td></tr></tbody></table><p>矩阵A的每一个元素代表着从每一个状态变成下一个状态的概率。如果仅仅从上面““更 高 地 举起 邓小平理论 的 伟大 旗帜”这句话以及其对应状态序列“SSSBEBMMMESBEBE”来看，状态转移概率矩阵A就是：</p><table><thead><tr><th></th><th>B</th><th>M</th><th>E</th><th>S</th></tr></thead><tbody><tr><td>B</td><td>0</td><td>1/14</td><td>3/14</td><td>0</td></tr><tr><td>M</td><td>0</td><td>2/14</td><td>1/14</td><td>0</td></tr><tr><td>E</td><td>2/14</td><td>0</td><td>0</td><td>1/14</td></tr><tr><td>S</td><td>2/14</td><td>0</td><td>0</td><td>2/14</td></tr></tbody></table></li><li><p>那么什么是我们的观测转移矩阵呢。每一个时刻的观测就是我们所看到的句子中的一个字，状态则是前面所说的BMES之一。那么可得出观测转移矩阵B是：</p><table><thead><tr><th></th><th>v1</th><th>v2</th><th>v3</th><th>v4</th><th>vM - 1</th><th>vM</th></tr></thead><tbody><tr><td>B</td><td>B to v1</td><td>B to v2</td><td>B to v3</td><td>B to v4</td><td>B to vM - 1</td><td>B to vM</td></tr><tr><td>M</td><td>M to v1</td><td>M to v2</td><td>M to v3</td><td>M to v4</td><td>M to vM - 1</td><td>M to vM</td></tr><tr><td>E</td><td>E to v1</td><td>E to v2</td><td>E to v3</td><td>E to v4</td><td>E to vM - 1</td><td>E to vM</td></tr><tr><td>S</td><td>S to v1</td><td>S to v2</td><td>S to v3</td><td>S to v5</td><td>S to vM - 1</td><td>S to vM</td></tr></tbody></table><p>如果仅仅从上面““更 高 地 举起 邓小平理论 的 伟大 旗帜”这句话以及其对应状态序列“SSSBEBMMMESBEBE”来看，观测转移矩阵B就是：</p><p>| |更|高|地|举|起| |邓|小|平|理|论|的|伟|大|旗|帜| |----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----| |B| | | |1/15| | |1/15| | | | | |1/15| |1/15| | |M| | | | | | | |1/15|1/15、1/15| | | | | | | | |E| | | | | |1/15| | | | |1/15| | |1/15| |1/15| |S|1/15|1/15、1/15| | | | | | | | |1/15| | | | | |</p></li><li><p>最后就是我们的初始状态概率向量 。初始状态概率向量形式：</p><p>|| --|-- B|P_B M|P_M E|P_E S|P_S</p><p>其实就是统计所有句子句首的状态出现次数，然后转换为频率。初始状态向量M和E所对应的b和c的值为0。因为句子只可能是B或S开头。还有矩阵A中M to S的概率为0等等。</p></li></ol><p>✨数学处理的小技巧</p><ol><li>如果句子较长，许多个较小的数值连乘，容易造成下溢。对于这种情况，我们常常使用log处理，那么之后计算概率的时候数值连乘就变为了log值相加了。</li><li>如果有一些没有出现的词语，导致矩阵对应位置0，那么测试的时候遇到了，连乘中有一个为0，整体就为0。但是log0是不存在的，我们需要做一些平滑处理，给每一个0的位置加上一个极小值（-3.14e+100)，使得其有定义。</li></ol><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考" aria-hidden="true">#</a> 参考</h2>',8),S={href:"https://zhuanlan.zhihu.com/p/116011442",target:"_blank",rel:"noopener noreferrer"};function i(n,p){const d=e("ExternalLinkIcon");return r(),h("div",null,[E,t("ul",null,[t("li",null,[t("a",S,[l("机器学习｜隐马尔可夫模型-中文分词实现"),a(d)])])])])}const _=o(B,[["render",i],["__file","hmm_应用.html.vue"]]);export{_ as default};
