const n=JSON.parse(`{"key":"v-67e5fa9c","path":"/8%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/3spark/function/dataframe.html","title":"dataframe","lang":"zh-CN","frontmatter":{"description":"dataframe create from RDD ## coding:utf8 from pyspark.sql import SparkSession ## 0. 构建执行环境入口对象SparkSession spark = SparkSession.builder.\\\\ appName(\\"test\\").\\\\ master(\\"local[*]\\").\\\\ getOrCreate() sc = spark.sparkContext ## 构建RDD rdd = sc.textFile(\\"../data/input/sql/people.txt\\").\\\\ map(lambda x: x.split(\\",\\")).\\\\ map(lambda x: (x[0], int(x[1]))) ## 构建DataFrame对象 ## 参数1 被转换的RDD ## 参数2 指定列名, 通过list的形式指定, 按照顺序依次提供字符串名称即可 df = spark.createDataFrame(rdd, schema=['name', 'age']) # 等价df1 = rdd.toDF([\\"name\\", \\"age\\"]) ## 打印DataFrame的表结构 df.printSchema() ## 打印df中的数据 ## 参数1 表示 展示出多少条数据, 默认不传的话是20 ## 参数2 表示是否对列进行截断, 如果列的数据长度超过20个字符串长度, 后续的内容不显示以...代替 ## 如果给False 表示不阶段全部显示, 默认是True df.show(20, False)","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/8%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/3spark/function/dataframe.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"dataframe"}],["meta",{"property":"og:description","content":"dataframe create from RDD ## coding:utf8 from pyspark.sql import SparkSession ## 0. 构建执行环境入口对象SparkSession spark = SparkSession.builder.\\\\ appName(\\"test\\").\\\\ master(\\"local[*]\\").\\\\ getOrCreate() sc = spark.sparkContext ## 构建RDD rdd = sc.textFile(\\"../data/input/sql/people.txt\\").\\\\ map(lambda x: x.split(\\",\\")).\\\\ map(lambda x: (x[0], int(x[1]))) ## 构建DataFrame对象 ## 参数1 被转换的RDD ## 参数2 指定列名, 通过list的形式指定, 按照顺序依次提供字符串名称即可 df = spark.createDataFrame(rdd, schema=['name', 'age']) # 等价df1 = rdd.toDF([\\"name\\", \\"age\\"]) ## 打印DataFrame的表结构 df.printSchema() ## 打印df中的数据 ## 参数1 表示 展示出多少条数据, 默认不传的话是20 ## 参数2 表示是否对列进行截断, 如果列的数据长度超过20个字符串长度, 后续的内容不显示以...代替 ## 如果给False 表示不阶段全部显示, 默认是True df.show(20, False)"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-24T12:46:58.000Z"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2025-02-24T12:46:58.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"dataframe\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-24T12:46:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[{"level":2,"title":"create","slug":"create","link":"#create","children":[{"level":3,"title":"from RDD","slug":"from-rdd","link":"#from-rdd","children":[]},{"level":3,"title":"StructType","slug":"structtype","link":"#structtype","children":[]}]},{"level":2,"title":"file","slug":"file","link":"#file","children":[{"level":3,"title":"text","slug":"text","link":"#text","children":[]},{"level":3,"title":"json","slug":"json","link":"#json","children":[]},{"level":3,"title":"csv","slug":"csv","link":"#csv","children":[]},{"level":3,"title":"parquet","slug":"parquet","link":"#parquet","children":[]}]},{"level":2,"title":"code style","slug":"code-style","link":"#code-style","children":[{"level":3,"title":"dsl","slug":"dsl","link":"#dsl","children":[]}]}],"git":{"createdTime":1740401218000,"updatedTime":1740401218000,"contributors":[{"name":"Claroja","email":"63183535@qq.com","commits":1}]},"readingTime":{"minutes":2.97,"words":892},"filePathRelative":"8数据工程/3spark/function/dataframe.md","localizedDate":"2025年2月24日","excerpt":"<h1> dataframe</h1>\\n<h2> create</h2>\\n<h3> from RDD</h3>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token comment\\">## coding:utf8</span>\\n\\n<span class=\\"token keyword\\">from</span> pyspark<span class=\\"token punctuation\\">.</span>sql <span class=\\"token keyword\\">import</span> SparkSession\\n<span class=\\"token comment\\">## 0. 构建执行环境入口对象SparkSession</span>\\nspark <span class=\\"token operator\\">=</span> SparkSession<span class=\\"token punctuation\\">.</span>builder<span class=\\"token punctuation\\">.</span>\\\\\\n    appName<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"test\\"</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>\\\\\\n    master<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"local[*]\\"</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>\\\\\\n    getOrCreate<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\nsc <span class=\\"token operator\\">=</span> spark<span class=\\"token punctuation\\">.</span>sparkContext\\n\\n<span class=\\"token comment\\">## 构建RDD</span>\\nrdd <span class=\\"token operator\\">=</span> sc<span class=\\"token punctuation\\">.</span>textFile<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\"../data/input/sql/people.txt\\"</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>\\\\\\n    <span class=\\"token builtin\\">map</span><span class=\\"token punctuation\\">(</span><span class=\\"token keyword\\">lambda</span> x<span class=\\"token punctuation\\">:</span> x<span class=\\"token punctuation\\">.</span>split<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">\\",\\"</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>\\\\\\n    <span class=\\"token builtin\\">map</span><span class=\\"token punctuation\\">(</span><span class=\\"token keyword\\">lambda</span> x<span class=\\"token punctuation\\">:</span> <span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">[</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> <span class=\\"token builtin\\">int</span><span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">[</span><span class=\\"token number\\">1</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\">## 构建DataFrame对象</span>\\n<span class=\\"token comment\\">## 参数1 被转换的RDD</span>\\n<span class=\\"token comment\\">## 参数2 指定列名, 通过list的形式指定, 按照顺序依次提供字符串名称即可</span>\\ndf <span class=\\"token operator\\">=</span> spark<span class=\\"token punctuation\\">.</span>createDataFrame<span class=\\"token punctuation\\">(</span>rdd<span class=\\"token punctuation\\">,</span> schema<span class=\\"token operator\\">=</span><span class=\\"token punctuation\\">[</span><span class=\\"token string\\">'name'</span><span class=\\"token punctuation\\">,</span> <span class=\\"token string\\">'age'</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span>  <span class=\\"token comment\\"># 等价df1 = rdd.toDF([\\"name\\", \\"age\\"])</span>\\n\\n<span class=\\"token comment\\">## 打印DataFrame的表结构</span>\\ndf<span class=\\"token punctuation\\">.</span>printSchema<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\">## 打印df中的数据</span>\\n<span class=\\"token comment\\">## 参数1 表示 展示出多少条数据, 默认不传的话是20</span>\\n<span class=\\"token comment\\">## 参数2 表示是否对列进行截断, 如果列的数据长度超过20个字符串长度, 后续的内容不显示以...代替</span>\\n<span class=\\"token comment\\">## 如果给False 表示不阶段全部显示, 默认是True</span>\\ndf<span class=\\"token punctuation\\">.</span>show<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">20</span><span class=\\"token punctuation\\">,</span> <span class=\\"token boolean\\">False</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","copyright":{"author":"王新宇"},"autoDesc":true}`);export{n as data};
