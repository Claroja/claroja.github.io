import{_ as t}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as p,c as e,e as a,a as s,b as n}from"./app-jdLxCr9I.js";const l="/assets/1-MyyVZsaL.png",o="/assets/2-cxYx1Wae.png",i="/assets/3-pZ6Lv_QF.png",c="/assets/5-rQXT1p-7.png",r="/assets/6-0DB8Iu9S.png",u="/assets/7-yi0XaKvG.png",m="/assets/8-QWcphSli.png",k="/assets/10-qyhP9Abs.png",d="/assets/11-tqFukSvm.png",h="/assets/12-S3JEU88e.png",g="/assets/100-zC4mdqB7.png",b="/assets/200-dc3c6upK.png",v="/assets/300-URV9Up1s.png",y="/assets/400-K7fOrJbE.png",w={},x=a('<h1 id="假设检验" tabindex="-1"><a class="header-anchor" href="#假设检验" aria-hidden="true">#</a> 假设检验</h1><h2 id="概念" tabindex="-1"><a class="header-anchor" href="#概念" aria-hidden="true">#</a> 概念</h2><p><code>统计假设检验(statistical hypothesis testing)</code>是一种统计学框架, 即建立关于总体参数的两个假设, 利用从样本中计算出的统计量来判断哪一个假设正确.</p><h2 id="理解假设检验的入门案例" tabindex="-1"><a class="header-anchor" href="#理解假设检验的入门案例" aria-hidden="true">#</a> 理解假设检验的入门案例</h2>',4),f=s("p",null,[n("饼干店老板声称他家的饼干一袋的平均重量("),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"μ")]),s("annotation",{encoding:"application/x-tex"},"\\mu")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"μ")])])]),n(")是500g. 由于是流水线生产, 所以每袋饼干的标准差("),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"σ")]),s("annotation",{encoding:"application/x-tex"},"\\sigma")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ")])])]),n(")为30g. 所以可得如下的分布:")],-1),_=s("figure",null,[s("img",{src:l,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),z=s("p",null,"这个店的老板会不会撒谎?我们如何确定平均重量是不是500g呢?这就需要假设检验(hypothesis testing)出场了.",-1),M=s("h3",{id:"提出假设",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#提出假设","aria-hidden":"true"},"#"),n(" 提出假设")],-1),H=s("ol",null,[s("li",null,[s("p",null,"先假设店老板是诚实的(H0, null hypothesis), 如果我们想检查他的饼干是不是少于500g, 我们需要搜集证据来支持我们的猜测(H1, alternative hypothesis):"),s("ol",null,[s("li",null,[n("H0: 每袋的重量"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"μ")]),s("annotation",{encoding:"application/x-tex"},"\\mu")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"μ")])])]),n("=500g")]),s("li",null,[n("H1: 每袋的重量"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"μ")]),s("annotation",{encoding:"application/x-tex"},"\\mu")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"μ")])])]),n("<500g")])])])],-1),q=a('<p>由于我们不知道整体的分布(population distribution), 所以使用虚线来表示. 如果店老板是诚实的, 那么分布就应该是左边的图片. 如果是小于500g, 则是右边的图片的某一个.</p><figure><img src="'+o+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="推断统计-inferential-statistics" tabindex="-1"><a class="header-anchor" href="#推断统计-inferential-statistics" aria-hidden="true">#</a> 推断统计(Inferential Statistics)</h3><p>我们无法得到所有饼干的重量, 既无法计算整体的分布. 所以我们可以通过抽样来估算.</p><ol><li>首先我们从整体中抽样得到抽样数据(sample), 计算出统计量(statistics), 如样本均值, 样本方差</li><li>然后通过统计量估算除整体(population)的参数(parameters), 如整体的均值, 整体方差</li></ol><p>Examples of parameters and statistics:</p><ul><li>parameters: population mean (μ), population standard deviation (σ)</li><li>statistics: sample mean (x̄), sample standard deviation (s)</li></ul><figure><img src="'+i+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="抽样分布" tabindex="-1"><a class="header-anchor" href="#抽样分布" aria-hidden="true">#</a> 抽样分布</h3>',9),X=s("p",null,[n("如果我们多次从整体中抽样, 我们可以获得多个抽样数据集. 我们计算每个抽样数据集的均值("),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n("), 通过这些均值可以画出抽样的均值分布.由于这个分布, 是由抽样统计得来, 所以我们称之为: Sampling Distribution of sample mean ("),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n("). 如下图, 使用棕色来代表样本分布曲线(sampling distribution curve).")],-1),P=s("figure",null,[s("img",{src:c,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),A=s("h3",{id:"验证假设-testing-hypothesis-statements",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#验证假设-testing-hypothesis-statements","aria-hidden":"true"},"#"),n(" 验证假设(Testing Hypothesis Statements)")],-1),L=s("ol",null,[s("li",null,"获得样本数据集, 我们获得25袋饼干, 计算其mean weight (x̄)=485g"),s("li",null,[n("假设"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"H_0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("为真, 既一袋饼干的整体分布为500g, 根据"),s("code",null,"中心极限定律"),n("(Central Limit Theorem,) 我们可以得到抽样均值(x̄)的分布.")])],-1),T=s("figure",null,[s("img",{src:r,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),S=s("p",null,[n("假设, 我们的抽样均值为485g, 相对于期望("),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"H_0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("假设)的(500g)低了15g(485-500=-15).")],-1),I=s("figure",null,[s("img",{src:u,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),O=s("p",null,'但是"15g"只是一个数字, 并不能作为解释. 另外我们想计算曲线下方的概率, 但是直接计算会非常的低效, 因为不同的曲线对应了不同的值.所以我们要对其进行标准化(standardize), 这样分布的均值为0.',-1),N=s("figure",null,[s("img",{src:m,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),G=s("p",null,[n("如果"),s("code",null,"H0"),n("成立, 则"),s("code",null,"population mean =500g, sample mean = 500g"),n(".而在这次抽样中, 我们的"),s("code",null,"sample mean = 485g"),n(", 计算后的"),s("code",null,"test statistic = -2.5"),n(". 表示样本均值有2.5个"),s("code",null,"标准差相对于期望值"),n("(expected value,"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"H_0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(").")],-1),R=s("p",null,[n("在这个场景中, 由于我们感兴趣的是均值, 而且假设整体是已知标准差(σ)的正态分布. 根据这些前提, 我们选择了"),s("code",null,"z-test"),n(". 那么在"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"H_0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("为真时, 获得这样的样本数据集的概率是多少呢?")],-1),E=s("p",null,[n("首先这个概率值,我们称为"),s("code",null,"p-value"),n(", 是下图中绿色的面积, 通过查询"),s("code",null,"z-table"),n(", 得到"),s("code",null,"p-value"),n("为0.0062")],-1),B=s("figure",null,[s("img",{src:k,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),C=s("p",null,[n("这是一个非常小的值, 它意味着在"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"H_0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("为真的条件下(整体的均值为500), 如果我们从整体中采样1000次, 有6.2次的机会获得这个样本集合(sample mean = 485g), 或者sample mean < 485g.")],-1),V=a('<p>换句话说: 如果我们获得一个mean=485g的采样数据集, 他们的解释有两个:</p><ol><li>population mean=500g(H0是正确的), 我们很&quot;幸运&quot;的获得了这个采样的数据集(P=0.0062)</li><li>H0是错误的, 这个mean=485g的采样数据集可能来自于其他的分布, 当然很可能是来自于mean = 485g 的分布.</li></ol><figure><img src="'+d+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>至于是使用第一个解释还是第二个解释,需要引入新的概念: 显著性水平(<code>significant level (α)</code>).这个值是再假设检验之前设置的, 它就是评判<code>p-value</code>的阈值:</p><ol><li>if p-value ≤ significant level (α), we reject the null hypothesis (H0).</li><li>if p-value &gt; significant level (α), we accept the null hypothesis (H0).</li></ol><p>我们设置显著性水平为0.05.如果p-value在红色区域, 我们就拒绝H0的假设;如果p-value大于红色区域, 我们就接收H0的假设.显著性水平是我们主观设置的阈值.</p><figure><img src="'+h+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',7),K=s("p",null,[n("在这个场景中, 我们的p-value=0.0062, 小于significant level (α)=0.05. 所以我们就拒绝了假设"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"H_0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(", 而接受了"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"H_1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(".")],-1),W=a(`<h2 id="python实操的一个案例" tabindex="-1"><a class="header-anchor" href="#python实操的一个案例" aria-hidden="true">#</a> python实操的一个案例</h2><p>A经常去便利店买红薯. 这份薯条标明的平均重量为130g. 有一天, A称了一下薯条的重量, 发现只有122.02g. A怀疑便利店的薯条实际平均重量达不到130g, 于是他连续两周每天都去买薯条并称重. 两周后, 他计算出这14个样本的平均值为128.451g. A认为14个样本的平均值明显低于130g, 便去便利店投诉. 但是便利店以这只是偶然情况拒绝了A的投诉. 那么14个样本的平均值128.451g比标重130g小真的只是偶然嘛?使用<strong>统计检验</strong>可以方便地判断其是否是偶然的.</p><p>首先使用python创建数据集:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> scipy <span class="token keyword">import</span> stats
sample <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">122.02</span><span class="token punctuation">,</span><span class="token number">131.73</span><span class="token punctuation">,</span><span class="token number">130.6</span><span class="token punctuation">,</span><span class="token number">131.82</span><span class="token punctuation">,</span><span class="token number">132.05</span><span class="token punctuation">,</span><span class="token number">126.12</span><span class="token punctuation">,</span><span class="token number">124.43</span><span class="token punctuation">,</span><span class="token number">132.89</span><span class="token punctuation">,</span><span class="token number">122.79</span><span class="token punctuation">,</span><span class="token number">129.95</span><span class="token punctuation">,</span><span class="token number">126.14</span><span class="token punctuation">,</span><span class="token number">134.45</span><span class="token punctuation">,</span><span class="token number">127.64</span><span class="token punctuation">,</span><span class="token number">125.68</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
s_mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>sample<span class="token punctuation">)</span>  <span class="token comment"># 128.451</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="统计假设检验的基础" tabindex="-1"><a class="header-anchor" href="#统计假设检验的基础" aria-hidden="true">#</a> 统计假设检验的基础</h3>`,5),Z=s("p",null,[n("A想确认薯条的总体平均值是否比130g少, 为此, "),s("code",null,"先假设薯条的重量服从正态分布"),n(", 总体方差为9, 则方差为"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mn",null,"9"),s("mn",null,"14")])]),s("annotation",{encoding:"application/x-tex"},"\\frac{9}{14}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1901em","vertical-align":"-0.345em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"9")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])],-1),D=s("p",null,[n("首先假设总体平均值为130g. 在这个假设下, 薯条的14个样本服从"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"X"),s("mn",null,"1")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"X"),s("mn",null,"2")]),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"X"),s("mn",null,"14")]),s("msup",null,[s("mo",null,"∼"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"i"),s("mi",null,"d")])]),s("mi",null,"N"),s("mo",{stretchy:"false"},"("),s("mn",null,"130"),s("mo",{separator:"true"},","),s("mfrac",null,[s("mn",null,"9"),s("mn",null,"14")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"X_1,X_2,...,X_{14} \\sim^{iid}N(130,\\frac{9}{14})")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0435em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},[s("span",{class:"mrel"},"∼"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8491em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ii"),s("span",{class:"mord mathnormal mtight"},"d")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1901em","vertical-align":"-0.345em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"130"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"9")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")")])])]),n(", 样本平均值"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n("服从"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N"),s("mo",{stretchy:"false"},"("),s("mn",null,"130"),s("mo",{separator:"true"},","),s("mfrac",null,[s("mn",null,"9"),s("mn",null,"14")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"N(130,\\frac{9}{14})")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1901em","vertical-align":"-0.345em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"130"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"9")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")")])])]),n(". 因为样本平均值"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n("是随机变量, 我们可以看到它可能低至125g, 也可能达到135g. 在此考虑样本平均值"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n("满足"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")]),s("mo",null,"≤"),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mn",null,"0.05")]),s("annotation",{encoding:"application/x-tex"},"P(\\overline{X} \\leq x)= 0.05")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1333em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≤"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0.05")])])]),n("的"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])]),n(".")],-1),F=a(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>rv <span class="token operator">=</span> stats<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token number">130</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">9</span><span class="token operator">/</span><span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
rv<span class="token punctuation">.</span>isf<span class="token punctuation">(</span><span class="token number">0.95</span><span class="token punctuation">)</span>  <span class="token comment"># 128.681</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div>`,1),U=s("p",null,[n("从"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")]),s("mo",null,"≤"),s("mn",null,"128.681"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mn",null,"0.05")]),s("annotation",{encoding:"application/x-tex"},"P(\\overline{X} \\leq 128.681)=0.05")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1333em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"("),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≤"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"128.681"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0.05")])])]),n(", 可知样本平均重量低于128.681g的概率为5%. 由此可确认, A拿到的样本平均值为128.451g是只有5%的概率发生的小概率事件.")],-1),Y=s("figure",null,[s("img",{src:g,alt:"",tabindex:"0",loading:"lazy"}),s("figcaption")],-1),j=s("p",null,'如果买到的炸薯条的样本平均值为128.451g, 肯定会有人觉得这样的事情发生的概率只有5%, 只是运气不好罢了. 但是进行假设检验的A不同意偶然这种说法, 他会觉得这个假设有问题. 也就是说, 样本平均值为128.451g, 在"总体平均值为130g"这个假设之下, 不能说是偶然发生了概率为5%的事件, 只能认为总体平均值低于130g, 由此可以得出总体平均值低于130g的结论. 这就是假设检验的大致流程.',-1),Q=s("p",null,[n("验证假设的过程中, 使用了关于总体的两个假设:"),s("strong",null,"零假设(null hypothesis)"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"H_0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("和"),s("strong",null,"备选假设(alternative hypothesis)"),n(),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"H_1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(".")],-1),J=a('<ol><li>备选假设主张的假设是&quot;有差别&quot; 或 &quot;有效果&quot;等内容,</li><li>零假设与备选假设相反, 是&quot;没有差别&quot;或&quot;没有效果&quot;等内容. 零假设和备选假设分别写作和.</li></ol><p>为了验证这两个假设, 需要从个样本中计算统计量进行假设检验, 得到的结论是&quot;<strong>拒绝零假设</strong>&quot;(reject the null hypothesis)或者&quot;<strong>接受零假设</strong>&quot;(accept the null hypothesis).</p><p>拒绝或接受零假设的判断, 是在假定零假设正确的基础上, 从样本中计算出的统计量取值是否为小概率事件来决定的. 是否为小概率事件是通过显著性水平来判断的, 这是一个主观的值.</p><p>备选假设是&quot;总体平均值低于130g&quot;, 而零假设主张的是&quot;总体均值是130g&quot;. 这个假设检验可能得到的结论是&quot;拒绝零假设&quot;, 即认为&quot;总体平均值低于130g&quot;, 或者&quot;接受零假设&quot;, 即认为&quot;总体平均值不低于130g&quot;. 请注意, 在假定零假设正确的情况下, 不能得出&quot;总体平均值为130g&quot;的结论.</p><p>如果样本平均值低于128.681g, 则拒绝零假设, 如果高于这个值, 则接受零假设. 像这样, 零假设被拒绝的区间称为<code>拒绝域</code>(rejectio region), 被接受的区间称为<code>接受域</code>(acceptance region). 上图中, 蓝色区间为拒绝域, 非蓝色区间为接受域, 而<code>拒绝域的面积就是进入拒绝域的概率</code>, 所以在假设检验中先确定这个概率再进行检验. 这个概率被称为<code>显著性水平</code>(level of significance), 进入拒绝域的阈值被称为<code>临界值</code>(critical value). 另外, 用于检验的统计量被称为<code>检验统计量</code>(test statistic). 在薯条的例子中, 显著性水平为5%, 检验统计量是样本均值, 临界值为128.681.</p><p>检验统计量小于临界值的情况如下图所示, <code>临界值左侧区域</code>的面积是<code>显著性水平</code>, 同样, <code>检验统计量左侧区域</code>的面积被称为<code>p值</code>(p-value).假设检验不仅可以<code>通过比较检验统计量和临界值进行</code>, 也可以<code>通过比较p值和显著性水平来进行</code>. 在这种情况下, 当p值低于显著性水平时, 将拒绝零假设, 否则将接受零假设.</p><figure><img src="'+b+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',7),$=s("p",null,[n('下面再来考虑一下薯条重量平均值的假设检验问题. 假设零假设"总体平均值为130g"正确, A买的'),s("code",null,"14分炸薯条"),n("相互独立的服从N(130,9), "),s("code",null,"样本平均值"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n("服从"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N"),s("mo",{stretchy:"false"},"("),s("mn",null,"130"),s("mo",{separator:"true"},","),s("mn",null,"9"),s("mi",{mathvariant:"normal"},"/"),s("mn",null,"14"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"N(130,9/14)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"130"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"9/14"),s("span",{class:"mclose"},")")])])]),n(". 刚才在检验统计量中使用样本平均值"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n(", 在这里将检验过程一般化, 使用样本平均值"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")])]),s("annotation",{encoding:"application/x-tex"},"\\overline{X}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8833em"}}),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])])])])]),n("的标准化变量"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Z"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")]),s("mo",null,"−"),s("mn",null,"130"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("msqrt",null,[s("mfrac",null,[s("mn",null,"9"),s("mn",null,"14")])])]),s("annotation",{encoding:"application/x-tex"},"Z=(\\overline{X}-130)/\\sqrt{\\frac{9}{14}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1333em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.84em","vertical-align":"-0.6049em"}}),s("span",{class:"mord"},"130"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/"),s("span",{class:"mord sqrt"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2351em"}},[s("span",{class:"svg-align",style:{top:"-3.8em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"mord",style:{"padding-left":"1em"}},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"9")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])]),s("span",{style:{top:"-3.1951em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"hide-tail",style:{"min-width":"1.02em",height:"1.88em"}},[s("svg",{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.88em",viewBox:"0 0 400000 1944",preserveAspectRatio:"xMinYMin slice"},[s("path",{d:`M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z`})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6049em"}},[s("span")])])])])])])]),n(". 通过标准化变换, 其上侧100"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"α")]),s("annotation",{encoding:"application/x-tex"},"\\alpha")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α")])])]),n("%分位点可以用"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"Z"),s("mi",null,"α")])]),s("annotation",{encoding:"application/x-tex"},"Z_\\alpha")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0715em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.0037em"}},"α")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("来表示, 临界值就是满足"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"P"),s("mo",{stretchy:"false"},"("),s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")]),s("mo",null,"−"),s("mn",null,"130"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("msqrt",null,[s("mfrac",null,[s("mn",null,"9"),s("mn",null,"14")])]),s("mo",null,"≤"),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mn",null,"0.05")]),s("annotation",{encoding:"application/x-tex"},"P((\\overline{X}-130)/\\sqrt{\\frac{9}{14}}\\leq x)=0.05")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1333em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"(("),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.84em","vertical-align":"-0.6049em"}}),s("span",{class:"mord"},"130"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/"),s("span",{class:"mord sqrt"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2351em"}},[s("span",{class:"svg-align",style:{top:"-3.8em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"mord",style:{"padding-left":"1em"}},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"9")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])]),s("span",{style:{top:"-3.1951em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"hide-tail",style:{"min-width":"1.02em",height:"1.88em"}},[s("svg",{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.88em",viewBox:"0 0 400000 1944",preserveAspectRatio:"xMinYMin slice"},[s("path",{d:`M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z`})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6049em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≤"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0.05")])])]),n("的"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])]),n(", 即"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"="),s("msub",null,[s("mi",null,"z"),s("mn",null,"0.95")])]),s("annotation",{encoding:"application/x-tex"},"x=z_{0.95}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0.95")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(".")],-1),ss=s("p",null,"在这个假设检验中, 当检验统计量比临界值小时就会拒绝零假设, 反之, 会接受零假设, 总结如下:",-1),ns=s("ol",null,[s("li",null,[n("若"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")]),s("mo",null,"−"),s("mn",null,"130"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("msqrt",null,[s("mfrac",null,[s("mn",null,"9"),s("mn",null,"14")])]),s("mo",null,"<"),s("msub",null,[s("mi",null,"z"),s("mn",null,"0.95")])]),s("annotation",{encoding:"application/x-tex"},"(\\overline{X}-130)/\\sqrt{\\frac{9}{14}} < z_{0.95}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1333em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.84em","vertical-align":"-0.6049em"}}),s("span",{class:"mord"},"130"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/"),s("span",{class:"mord sqrt"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2351em"}},[s("span",{class:"svg-align",style:{top:"-3.8em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"mord",style:{"padding-left":"1em"}},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"9")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])]),s("span",{style:{top:"-3.1951em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"hide-tail",style:{"min-width":"1.02em",height:"1.88em"}},[s("svg",{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.88em",viewBox:"0 0 400000 1944",preserveAspectRatio:"xMinYMin slice"},[s("path",{d:`M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z`})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6049em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"<"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0.95")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])]),s("li",null,[n("若"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mover",{accent:"true"},[s("mi",null,"X"),s("mo",{stretchy:"true"},"‾")]),s("mo",null,"−"),s("mn",null,"130"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("msqrt",null,[s("mfrac",null,[s("mn",null,"9"),s("mn",null,"14")])]),s("mo",null,"≥"),s("msub",null,[s("mi",null,"z"),s("mn",null,"0.95")])]),s("annotation",{encoding:"application/x-tex"},"(\\overline{X}-130)/\\sqrt{\\frac{9}{14}} \\ge z_{0.95}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1333em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord overline"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8833em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X")])]),s("span",{style:{top:"-3.8033em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.84em","vertical-align":"-0.6049em"}}),s("span",{class:"mord"},"130"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/"),s("span",{class:"mord sqrt"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2351em"}},[s("span",{class:"svg-align",style:{top:"-3.8em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"mord",style:{"padding-left":"1em"}},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"14")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"9")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])]),s("span",{style:{top:"-3.1951em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"hide-tail",style:{"min-width":"1.02em",height:"1.88em"}},[s("svg",{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.88em",viewBox:"0 0 400000 1944",preserveAspectRatio:"xMinYMin slice"},[s("path",{d:`M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z`})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6049em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≥"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.044em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0.95")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])])],-1),as=a(`<p>用python来计算:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>z <span class="token operator">=</span> <span class="token punctuation">(</span>s_mean <span class="token operator">-</span> <span class="token number">130</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">9</span><span class="token operator">/</span><span class="token number">14</span><span class="token punctuation">)</span> <span class="token comment"># 检验统计量</span>
rv <span class="token operator">=</span> stats<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span>
rv<span class="token punctuation">.</span>isf<span class="token punctuation">(</span><span class="token number">0.95</span><span class="token punctuation">)</span>  <span class="token comment"># -1.645 计算临界值</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>比较检验统计量和临界值, 发现检验统计量比临界值小. 由此可以得出结论: 拒绝零假设, 认为总体平均值低于130g. 使用p值的假设检验也要确认, 首先从检验统计量中求出p值, p值可以使用累积分布函数:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>rv<span class="token punctuation">.</span>cdf<span class="token punctuation">(</span>z<span class="token punctuation">)</span>  <span class="token comment"># 0.027</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>p值为0.027, 明显小于显著性水平0.05, 所以拒绝零假设. 以p值为基准的假设检验也得到了与之前相同的结论.将以p值为基准的假设检验流程汇总为下图:</p><figure><img src="`+v+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="单侧检验和双侧检验" tabindex="-1"><a class="header-anchor" href="#单侧检验和双侧检验" aria-hidden="true">#</a> 单侧检验和双侧检验</h3><p>因为A只对薯条的平均值是否低于130g有兴趣, 所以以&quot;总体平均值比130g少&quot;的备选假设进行假设检验. 除此之外, 也可以将&quot;总体平均值不是130g&quot;设为备选假设进行假设检验. 这种情况下, 总体平均值不仅可以低于130g, 也可以高于130g. 这种检验叫做双侧检验. 另外像A那样只是在一侧进行的检验叫做单侧检验.</p>',8),ts=s("p",null,[n("单侧检验和双侧检验的拒绝域不同. 即使是对同等显著性水平"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"α")]),s("annotation",{encoding:"application/x-tex"},"\\alpha")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α")])])]),n("的检验, 从同一侧来看, 单侧检验的拒绝域范围更广. 因此单侧检验比双侧检验更容易拒绝零假设.")],-1),ps=a('<figure><img src="'+y+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>z <span class="token operator">=</span> <span class="token punctuation">(</span>s_mean <span class="token operator">-</span> <span class="token number">130</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">9</span><span class="token operator">/</span><span class="token number">14</span><span class="token punctuation">)</span>  <span class="token comment"># -1.932</span>
rv <span class="token operator">=</span> stats<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span>
rv<span class="token punctuation">.</span>interval<span class="token punctuation">(</span><span class="token number">0.95</span><span class="token punctuation">)</span>  <span class="token comment"># (-1.960, 1.960)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过比较临界值和检验统计量, 可以发现体验统计量进入了接受域. 也就是说, 双侧检验不能拒绝零假设. 请记住这样有个事实: 单侧检验与双侧检验相比, 单侧检验更容易拒绝零假设. 双侧检验的p值需要考虑上和下两部分的面积, 所以需要将累积分布函数的值设为原来的2倍.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>rv<span class="token punctuation">.</span>cdf<span class="token punctuation">(</span>z<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span>  <span class="token comment"># 0.053</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="一些常见的检验方法" tabindex="-1"><a class="header-anchor" href="#一些常见的检验方法" aria-hidden="true">#</a> 一些常见的检验方法</h2><ol><li><p>Normality Tests: 用来检测数据集是否是Gaussian distribution.</p><ol><li><p>Shapiro-Wilk Test: 数据集是否是Gaussian distribution.</p><ol><li><p>Assumptions: independent and identically distributed (iid).独立同分布</p></li><li><p>Interpretation</p><ul><li>H0: 数据集是Gaussian distribution.</li><li>H1: 数据集不是Gaussian distribution.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> shapiro
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> shapiro<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably Gaussian&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably not Gaussian&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>D’Agostino’s K^2 Test</p><ol><li><p>Assumptions: independent and identically distributed (iid).独立同分布</p></li><li><p>Interpretation</p><ul><li>0: 数据集是Gaussian distribution.</li><li>1: 数据集不是Gaussian distribution.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> normaltest
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> normaltest<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably Gaussian&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably not Gaussian&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Anderson-Darling Test</p><ol><li><p>Assumptions: independent and identically distributed (iid).独立同分布</p></li><li><p>Interpretation</p><ul><li>H0: 数据集是Gaussian distribution.</li><li>H1: 数据集不是Gaussian distribution.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> anderson
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
result <span class="token operator">=</span> anderson<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>result<span class="token punctuation">.</span>statistic<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>critical_values<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	sl<span class="token punctuation">,</span> cv <span class="token operator">=</span> result<span class="token punctuation">.</span>significance_level<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">.</span>critical_values<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
	<span class="token keyword">if</span> result<span class="token punctuation">.</span>statistic <span class="token operator">&lt;</span> cv<span class="token punctuation">:</span>
		<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably Gaussian at the %.1f%% level&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>sl<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword">else</span><span class="token punctuation">:</span>
		<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably not Gaussian at the %.1f%% level&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>sl<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li></ol></li><li><p>Correlation Tests: 测试两个样本集是否是相关的(related)</p><ol><li><p>Pearson’s Correlation Coefficient: 测试两个样本集是否是线性关系(linear relationship)</p><ol><li><p>Assumptions</p><ol><li>independent and identically distributed (iid). 独立同分布</li><li>normally distributed. 正太分布</li><li>same variance. 相同的方差</li></ol></li><li><p>Interpretation</p><ul><li>H0: the two samples are independent.</li><li>H1: there is a dependency between the samples.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> pearsonr
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.353</span><span class="token punctuation">,</span> <span class="token number">3.517</span><span class="token punctuation">,</span> <span class="token number">0.125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">7.545</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.555</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.536</span><span class="token punctuation">,</span> <span class="token number">3.350</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.578</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.537</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.579</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> pearsonr<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably independent&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably dependent&#39;</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Spearman’s Rank Correlation: 测试两个样本集是否是monotonic relationship.</p><ol><li><p>Assumptions</p><ol><li>independent and identically distributed (iid). 独立同分布</li><li>sample can be ranked. 样本可排序</li></ol></li><li><p>Interpretation</p><ul><li>H0: the two samples are independent.</li><li>H1: there is a dependency between the samples.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> spearmanr
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.353</span><span class="token punctuation">,</span> <span class="token number">3.517</span><span class="token punctuation">,</span> <span class="token number">0.125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">7.545</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.555</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.536</span><span class="token punctuation">,</span> <span class="token number">3.350</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.578</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.537</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.579</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> spearmanr<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably independent&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably dependent&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Kendall’s Rank Correlation: 测试两个样本集是否是monotonic relationship.</p><ol><li><p>Assumptions</p><ol><li>independent and identically distributed (iid). 独立同分布</li><li>sample can be ranked. 样本可排序</li></ol></li><li><p>Interpretation</p><ul><li>H0: the two samples are independent.</li><li>H1: there is a dependency between the samples.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> kendalltau
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.353</span><span class="token punctuation">,</span> <span class="token number">3.517</span><span class="token punctuation">,</span> <span class="token number">0.125</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">7.545</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.555</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.536</span><span class="token punctuation">,</span> <span class="token number">3.350</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.578</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.537</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.579</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> kendalltau<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably independent&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably dependent&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Chi-Squared Test: 测试两个categorical variables是related or independent</p><ol><li><p>Assumptions Observations used in the calculation of the contingency table are independent. 25 or more examples in each cell of the contingency table.</p></li><li><p>Interpretation</p><ul><li>H0: the two samples are independent.</li><li>H1: there is a dependency between the samples.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token number">1.</span> Example of the Chi<span class="token operator">-</span>Squared Test
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> chi2_contingency
table <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span>  <span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p<span class="token punctuation">,</span> dof<span class="token punctuation">,</span> expected <span class="token operator">=</span> chi2_contingency<span class="token punctuation">(</span>table<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably independent&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably dependent&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li></ol></li><li><p>Stationary Tests: 测试时间序列是stationary or not.</p><ol><li><p>Augmented Dickey-Fuller Unit Root Test: 测试一个time series是否有一个unit root.例如是否有某个趋势,更简单点是否是autoregressive.</p><ol><li><p>Assumptions Observations in are temporally ordered.</p></li><li><p>Interpretation</p><ul><li>H0: a unit root is present (series is non-stationary).</li><li>H1: a unit root is not present (series is stationary).</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>stattools <span class="token keyword">import</span> adfuller
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p<span class="token punctuation">,</span> lags<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> crit<span class="token punctuation">,</span> t <span class="token operator">=</span> adfuller<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably not Stationary&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably Stationary&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Kwiatkowski-Phillips-Schmidt-Shin: 测试时间序列是stationary or not.</p><ol><li><p>Assumptions: Observations in are temporally ordered.</p></li><li><p>Interpretation</p><ul><li>H0: a unit root is present (series is non-stationary).</li><li>H1: a unit root is not present (series is stationary).</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>stattools <span class="token keyword">import</span> kpss
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p<span class="token punctuation">,</span> lags<span class="token punctuation">,</span> crit <span class="token operator">=</span> kpss<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably not Stationary&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably Stationary&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li></ol></li><li><p>Parametric Statistical Hypothesis Tests: 用来比较两个数据样本的statistical tests</p><ol><li><p>Student’s t-test: 比较两个独立的样本集的均值是显著不同的</p><ol><li><p>Assumptions</p><ol><li>independent and identically distributed (iid). 独立同分布</li><li>normally distributed. 正态分布</li><li>same variance. 相同的方差</li></ol></li><li><p>Interpretation</p><ul><li>H0: the means of the samples are equal.</li><li>H1: the means of the samples are unequal.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> ttest_ind
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.432</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.938</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.729</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.846</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.157</span><span class="token punctuation">,</span> <span class="token number">0.500</span><span class="token punctuation">,</span> <span class="token number">1.183</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.075</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.169</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> ttest_ind<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably the same distribution&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably different distributions&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Paired Student’s t-test: Tests whether the means of two paired samples are significantly different.</p><ol><li><p>Assumptions</p><ol><li>independent and identically distributed (iid).</li><li>normally distributed.</li><li>same variance.</li><li>Observations across each sample are paired. 连个样本集的数据可以两两配对</li></ol></li><li><p>Interpretation</p><ul><li>H0: the means of the samples are equal.</li><li>H1: the means of the samples are unequal.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> ttest_rel
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.432</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.938</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.729</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.846</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.157</span><span class="token punctuation">,</span> <span class="token number">0.500</span><span class="token punctuation">,</span> <span class="token number">1.183</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.075</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.169</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> ttest_rel<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably the same distribution&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably different distributions&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Analysis of Variance Test (ANOVA): 两个或多个独立样本是否显著不同</p><ol><li><p>Assumptions</p><ul><li>bservations in each sample are independent and identically distributed (iid).</li><li>bservations in each sample are normally distributed.</li><li>bservations in each sample have the same variance.</li></ul></li><li><p>Interpretation</p><ul><li>H0: the means of the samples are equal.</li><li>H1: one or more of the means of the samples are unequal.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token number">1.</span> Example of the Analysis of Variance Test
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> f_oneway
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.432</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.938</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.729</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.846</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.157</span><span class="token punctuation">,</span> <span class="token number">0.500</span><span class="token punctuation">,</span> <span class="token number">1.183</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.075</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.169</span><span class="token punctuation">]</span>
data3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.208</span><span class="token punctuation">,</span> <span class="token number">0.696</span><span class="token punctuation">,</span> <span class="token number">0.928</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.148</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.213</span><span class="token punctuation">,</span> <span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.137</span><span class="token punctuation">,</span> <span class="token number">0.269</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.870</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.204</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> f_oneway<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">,</span> data3<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably the same distribution&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably different distributions&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Repeated Measures ANOVA Test: 两个或多个成对的独立样本是否显著不同</p><ol><li>Assumptions <ul><li>Observations in each sample are independent and identically distributed (iid).</li><li>Observations in each sample are normally distributed.</li><li>Observations in each sample have the same variance.</li><li>Observations across each sample are paired.</li></ul></li><li>Interpretation <ul><li>H0: the means of the samples are equal.</li><li>H1: one or more of the means of the samples are unequal.</li></ul></li></ol></li></ol></li><li><p>Nonparametric Statistical Hypothesis Tests: 两个独立样本分布是否相同</p><ol><li><p>Mann-Whitney U Test: 两个独立样本分布是否相同</p><ol><li><p>Assumptions</p><ol><li>independent and identically distributed (iid). 独立同分布</li><li>Observations in each sample can be ranked. 可以排序</li></ol></li><li><p>Interpretation</p><ul><li>H0: the distributions of both samples are equal.</li><li>H1: the distributions of both samples are not equal.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> mannwhitneyu
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.432</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.938</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.729</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.846</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.157</span><span class="token punctuation">,</span> <span class="token number">0.500</span><span class="token punctuation">,</span> <span class="token number">1.183</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.075</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.169</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> mannwhitneyu<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably the same distribution&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably different distributions&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Wilcoxon Signed-Rank Test: 两个成对的独立样本集分布是否相同</p><ol><li><p>Assumptions</p><ul><li>independent and identically distributed (iid).</li><li>Observations in each sample can be ranked.</li><li>Observations across each sample are paired.</li></ul></li><li><p>Interpretation</p><ul><li>H0: the distributions of both samples are equal.</li><li>H1: the distributions of both samples are not equal.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>
<span class="token number">1.</span> Example of the Wilcoxon Signed<span class="token operator">-</span>Rank Test
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> wilcoxon
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.432</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.938</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.729</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.846</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.157</span><span class="token punctuation">,</span> <span class="token number">0.500</span><span class="token punctuation">,</span> <span class="token number">1.183</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.075</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.169</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> wilcoxon<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably the same distribution&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably different distributions&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li><li><p>Kruskal-Wallis H Test: 两个或更多的独立样本集分布是否相同</p><ol><li><p>Assumptions</p><ul><li>Observations in each sample are independent and identically distributed (iid).</li><li>Observations in each sample can be ranked.</li></ul></li><li><p>Interpretation</p><ul><li>H0: the distributions of all samples are equal.</li><li>H1: the distributions of one or more samples are not equal.</li></ul></li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>
<span class="token number">1.</span> Example of the Kruskal<span class="token operator">-</span>Wallis H Test
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> kruskal
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.432</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.938</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.729</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.846</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.157</span><span class="token punctuation">,</span> <span class="token number">0.500</span><span class="token punctuation">,</span> <span class="token number">1.183</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.075</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.169</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> kruskal<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably the same distribution&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably different distributions&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Friedman Test: 两个或更多的成对的独立样本集分布是否相同</p><ol><li><p>Assumptions</p><ol><li>independent and identically distributed (iid).</li><li>Observations in each sample can be ranked.</li><li>Observations across each sample are paired.</li></ol></li><li><p>Interpretation</p><ul><li>H0: the distributions of all samples are equal.</li><li>H1: the distributions of one or more samples are not equal.</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token number">1.</span> Example of the Friedman Test
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> friedmanchisquare
data1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.873</span><span class="token punctuation">,</span> <span class="token number">2.817</span><span class="token punctuation">,</span> <span class="token number">0.121</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.945</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.055</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.436</span><span class="token punctuation">,</span> <span class="token number">0.360</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.478</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.637</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.869</span><span class="token punctuation">]</span>
data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.432</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.938</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.729</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.846</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.157</span><span class="token punctuation">,</span> <span class="token number">0.500</span><span class="token punctuation">,</span> <span class="token number">1.183</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.075</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.169</span><span class="token punctuation">]</span>
data3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.208</span><span class="token punctuation">,</span> <span class="token number">0.696</span><span class="token punctuation">,</span> <span class="token number">0.928</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.148</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.213</span><span class="token punctuation">,</span> <span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.137</span><span class="token punctuation">,</span> <span class="token number">0.269</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.870</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.204</span><span class="token punctuation">]</span>
stat<span class="token punctuation">,</span> p <span class="token operator">=</span> friedmanchisquare<span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">,</span> data3<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;stat=%.3f, p=%.3f&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>stat<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> p <span class="token operator">&gt;</span> <span class="token number">0.05</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably the same distribution&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;Probably different distributions&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol></li></ol></li></ol><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考" aria-hidden="true">#</a> 参考</h2><ul><li>https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/</li><li>https://www.kaggle.com/hamelg/python-for-data-24-hypothesis-testing</li><li>https://analyticsindiamag.com/10-most-popular-statistical-hypothesis-testing-methods-using-python/</li><li>https://inblog.in/Hypothesis-Testing-using-Python-RqrE4uDqMe</li><li>https://towardsdatascience.com/what-is-p-value-370056b8244d</li></ul>`,8),es=[x,f,_,z,M,H,q,X,P,A,L,T,S,I,O,N,G,R,E,B,C,V,K,W,Z,D,F,U,Y,j,Q,J,$,ss,ns,as,ts,ps];function ls(os,is){return p(),e("div",null,es)}const us=t(w,[["render",ls],["__file","1_1假设检验_直观理解.html.vue"]]);export{us as default};
