const e=JSON.parse(`{"key":"v-309704b0","path":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/supply/regularization.html","title":"regularization","lang":"zh-CN","frontmatter":{"description":"regularization Let's start by collecting weight and size measurements from a bunch of mice.Since these data look relatively linear, we will use linear regression, AKA least squares, to model the relationship between weight and size.In others words, we find the line that results in the minimum sum of squared residuals. Ultimately, we end up with this equation for the line:Size=0.9+0.75∗weightSize = 0.9 + 0.75 * weightSize=0.9+0.75∗weight. The line has two parameters: a y-axis intercept(0.9) and a slope(0.75). When we have a lot of measurements, we can be fairly confident that the Least Squares line accurately reflects the relationship between Size and Weight. But what if we only have two measurements? We fit a new line(red) with least squares. Since the new line overlaps the two data points, the minimum sum of squares residuals = 0.Ultimately, we end up with this equation for the new line:Size=0.4+1.3∗weightSize=0.4+1.3*weightSize=0.4+1.3∗weight NOTE: Here are the original data and the original line(grey) for comparison.Let's call the two red dots the training data, and the remaining green dots the testing data.","head":[["meta",{"property":"og:url","content":"https://claroja.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/supply/regularization.html"}],["meta",{"property":"og:site_name","content":"Claroja"}],["meta",{"property":"og:title","content":"regularization"}],["meta",{"property":"og:description","content":"regularization Let's start by collecting weight and size measurements from a bunch of mice.Since these data look relatively linear, we will use linear regression, AKA least squares, to model the relationship between weight and size.In others words, we find the line that results in the minimum sum of squared residuals. Ultimately, we end up with this equation for the line:Size=0.9+0.75∗weightSize = 0.9 + 0.75 * weightSize=0.9+0.75∗weight. The line has two parameters: a y-axis intercept(0.9) and a slope(0.75). When we have a lot of measurements, we can be fairly confident that the Least Squares line accurately reflects the relationship between Size and Weight. But what if we only have two measurements? We fit a new line(red) with least squares. Since the new line overlaps the two data points, the minimum sum of squares residuals = 0.Ultimately, we end up with this equation for the new line:Size=0.4+1.3∗weightSize=0.4+1.3*weightSize=0.4+1.3∗weight NOTE: Here are the original data and the original line(grey) for comparison.Let's call the two red dots the training data, and the remaining green dots the testing data."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://claroja.github.io/"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-11-27T13:31:52.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"regularization"}],["meta",{"property":"article:author","content":"claroja"}],["meta",{"property":"article:modified_time","content":"2023-11-27T13:31:52.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"regularization\\",\\"image\\":[\\"https://claroja.github.io/\\"],\\"dateModified\\":\\"2023-11-27T13:31:52.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"claroja\\",\\"url\\":\\"https://claroja.github.io\\"}]}"]]},"headers":[],"git":{"createdTime":1701091021000,"updatedTime":1701091912000,"contributors":[{"name":"claroja","email":"63183535@qq.com","commits":2}]},"readingTime":{"minutes":1.97,"words":592},"filePathRelative":"机器学习/深度学习/supply/regularization.md","localizedDate":"2023年11月27日","excerpt":"<h1> regularization</h1>\\n<p>Let's start by collecting <code>weight</code> and <code>size</code> measurements from a bunch of mice.Since these data look relatively linear, we will use linear regression, AKA least squares, to model the relationship between weight and size.In others words, we find the line that results in the minimum sum of squared residuals.\\n\\nUltimately, we end up with this equation for the line:<span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mn>0.9</mn><mo>+</mo><mn>0.75</mn><mo>∗</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow><annotation encoding=\\"application/x-tex\\">Size = 0.9 + 0.75 * weight</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6833em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.05764em;\\">S</span><span class=\\"mord mathnormal\\">i</span><span class=\\"mord mathnormal\\">ze</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.7278em;vertical-align:-0.0833em;\\"></span><span class=\\"mord\\">0.9</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">+</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">0.75</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">∗</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.8889em;vertical-align:-0.1944em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.02691em;\\">w</span><span class=\\"mord mathnormal\\">e</span><span class=\\"mord mathnormal\\">i</span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.03588em;\\">g</span><span class=\\"mord mathnormal\\">h</span><span class=\\"mord mathnormal\\">t</span></span></span></span>. The line has two parameters: a y-axis intercept(0.9) and a slope(0.75).\\nWhen we have a lot of measurements, we can be fairly confident that the <code>Least Squares</code> line accurately reflects the relationship between <code>Size</code> and <code>Weight</code>. But what if we only have two measurements? We fit a new line(red) with least squares. Since the new line overlaps the two data points, the minimum sum of squares residuals = 0.Ultimately, we end up with this equation for the new line:<span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mn>0.4</mn><mo>+</mo><mn>1.3</mn><mo>∗</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow><annotation encoding=\\"application/x-tex\\">Size=0.4+1.3*weight</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6833em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.05764em;\\">S</span><span class=\\"mord mathnormal\\">i</span><span class=\\"mord mathnormal\\">ze</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.7278em;vertical-align:-0.0833em;\\"></span><span class=\\"mord\\">0.4</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">+</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">1.3</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">∗</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.8889em;vertical-align:-0.1944em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.02691em;\\">w</span><span class=\\"mord mathnormal\\">e</span><span class=\\"mord mathnormal\\">i</span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.03588em;\\">g</span><span class=\\"mord mathnormal\\">h</span><span class=\\"mord mathnormal\\">t</span></span></span></span>\\n\\nNOTE: Here are the original data and the original line(grey) for comparison.Let's call the two red dots the training data, and the remaining green dots the testing data.\\n</p>","copyright":{"author":"王新宇"},"autoDesc":true}`);export{e as data};
